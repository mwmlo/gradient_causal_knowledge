{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7d0ee836",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Gradient-based Counterfactuals in GPT2-Small\"\n",
    "format:\n",
    "    html:\n",
    "        code-fold: true\n",
    "        toc: true\n",
    "        toc-location: left\n",
    "        embed-resources: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b41d632",
   "metadata": {},
   "source": [
    "# Background, motivation and set up\n",
    "\n",
    "*Objective*: investigate the relationship between attribution scores and output gradients, and utilise this relationship to generate the \"optimal\" counterfactual inputs such that a specific model component will be assigned high attribution scores by IG/AP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr._utils.approximation_methods import approximation_parameters\n",
    "\n",
    "from transformer_lens.utils import get_act_name, get_device\n",
    "from transformer_lens import ActivationCache, HookedTransformer, HookedTransformerConfig\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = get_device()\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "n_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: true\n",
    "\n",
    "clean_prompt = \"After John and Mary went to the store, Mary gave a bottle of milk to\"\n",
    "corrupted_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "\n",
    "clean_input = model.to_tokens(clean_prompt)\n",
    "corrupted_input = model.to_tokens(corrupted_prompt)\n",
    "\n",
    "def logits_to_logit_diff(logits, correct_answer=\" John\", incorrect_answer=\" Mary\"):\n",
    "    # model.to_single_token maps a string value of a single token to the token index for that token\n",
    "    correct_index = model.to_single_token(correct_answer)\n",
    "    incorrect_index = model.to_single_token(incorrect_answer)\n",
    "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
    "\n",
    "# Explicitly calculate and expose the result for each attention head\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_hook_mlp_in(True)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_input)\n",
    "clean_logit_diff = logits_to_logit_diff(clean_logits)\n",
    "print(f\"Clean logit difference: {clean_logit_diff.item():.3f}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_input)\n",
    "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a34fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_from_layer_fn(x, original_input, prev_layer, reset_hooks_end=True):\n",
    "    # Force the layer before the target layer to output the given values, i.e. pass the given input into the target layer\n",
    "    # original_input value does not matter; useful to keep shapes nice, but its activations will be overwritten\n",
    "    \n",
    "    def fwd_hook(act, hook):\n",
    "        x.requires_grad_(True)\n",
    "        return x\n",
    "    \n",
    "    logits = model.run_with_hooks(\n",
    "        original_input,\n",
    "        fwd_hooks=[(prev_layer.name, fwd_hook)],\n",
    "        reset_hooks_end=reset_hooks_end\n",
    "    )\n",
    "    logit_diff = logits_to_logit_diff(logits).unsqueeze(0)\n",
    "    return logit_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9886a1",
   "metadata": {},
   "source": [
    "# Gradients with respect to interpolated inputs\n",
    "\n",
    "We take the change in model output with respect to the interpolated input at the target component. We quantify the change in gradients as the maximum range of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0482d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_attn_interpolated_outputs(target_layer_num, target_pos):\n",
    "    hook_name = get_act_name(\"result\", target_layer_num)\n",
    "    target_layer = model.hook_dict[hook_name]\n",
    "\n",
    "    layer_clean_input = clean_cache[hook_name] # Baseline\n",
    "\n",
    "    # Only corrupt at target head\n",
    "    layer_corrupt_input = layer_clean_input.clone()\n",
    "    layer_corrupt_input[:, :, target_pos] = corrupted_cache[hook_name][:, :, target_pos]\n",
    "\n",
    "    # Take the model starting from the target layer\n",
    "    forward_fn = lambda x: run_from_layer_fn(x, clean_input, target_layer)\n",
    "    _, alphas_func = approximation_parameters(\"gausslegendre\")\n",
    "    alphas = alphas_func(n_steps)\n",
    "\n",
    "    interpolated_inputs = [layer_clean_input + alpha * (layer_corrupt_input - layer_clean_input) for alpha in alphas]\n",
    "    outputs = [forward_fn(i) for i in interpolated_inputs]\n",
    "\n",
    "    print(outputs)\n",
    "\n",
    "    plt.title(f\"Model output at interpolated gradients: head {(target_layer_num, target_pos)}\")\n",
    "    plt.plot([o.item() for o in outputs])\n",
    "    plt.xlabel(\"Interpolation coefficient\")\n",
    "    plt.ylabel(\"Output (logit difference)\")\n",
    "    plt.ylim(0, 6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c13969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_baseline_inputs(target_layer_num, target_pos, clean_cache, corrupt_cache):\n",
    "    hook_name = get_act_name(\"result\", target_layer_num)\n",
    "    target_layer = model.hook_dict[hook_name]\n",
    "\n",
    "    layer_baseline = clean_cache[hook_name] # Baseline\n",
    "    layer_input = layer_baseline.clone()\n",
    "    layer_input[:, :, target_pos] = corrupt_cache[hook_name][:, :, target_pos]\n",
    "\n",
    "    return layer_baseline, layer_input, target_layer\n",
    "\n",
    "\n",
    "# Calculate attribution score based on mean over each embedding, for each token\n",
    "def mean_attribution(attribution_scores, pos=None):\n",
    "    per_token_score = attribution_scores.mean(dim=3)\n",
    "    score = per_token_score.mean(dim=1)\n",
    "    if pos is None:\n",
    "        return score\n",
    "    return score[:, pos]\n",
    "\n",
    "\n",
    "def attn_interpolated_gradients(target_layer_num, target_pos):\n",
    "    # Get the baseline inputs\n",
    "    layer_baseline, layer_input, target_layer = get_layer_baseline_inputs(target_layer_num, target_pos, clean_cache, corrupted_cache)\n",
    "    forward_fn = lambda x: run_from_layer_fn(x, clean_input, target_layer, reset_hooks_end=False)\n",
    "\n",
    "    # Get interpolated inputs according to step sizes\n",
    "    _, alphas_func = approximation_parameters(\"gausslegendre\")\n",
    "    alphas = alphas_func(n_steps)\n",
    "    interpolated_inputs = [layer_baseline + alpha * (layer_input - layer_baseline) for alpha in alphas]\n",
    "\n",
    "    # Calculate gradient of output with respect to interpolated inputs at target attention head\n",
    "    _, seq_len, _, d_model = layer_input.shape\n",
    "    grad_history = torch.zeros((n_steps, seq_len, 1, d_model))\n",
    "\n",
    "    with torch.autograd.set_grad_enabled(True):\n",
    "        for idx, i in enumerate(interpolated_inputs):\n",
    "            output = forward_fn(i)\n",
    "            grad = torch.autograd.grad(output, i)[0] # Shape (seq_len, n_heads, d_model)\n",
    "            model.reset_hooks()\n",
    "\n",
    "            # Take the gradient at target attention head\n",
    "            grad_history[idx] = grad[:, target_pos, :]\n",
    "\n",
    "    # ALTERNATIVE IMPLEMENTATION: CHECK RESULTS\n",
    "    # with torch.autograd.set_grad_enabled(True):\n",
    "    #     outputs = forward_fn(interpolated_inputs)\n",
    "    #     grads = torch.autograd.grad(outputs, interpolated_inputs)[0] # Shape (n_steps, seq_len, n_heads, d_model)\n",
    "    #     model.reset_hooks()\n",
    "\n",
    "    #     # Take the gradient at target attention head\n",
    "    #     grad_history = grads[:, :, target_pos, :]\n",
    "\n",
    "    return alphas, grad_history\n",
    "\n",
    "\n",
    "def quantify_gradients_range(mean_grad_history):\n",
    "    # Expected input shape: (n_steps, 1)\n",
    "    max_grad = torch.max(mean_grad_history)\n",
    "    min_grad = torch.min(mean_grad_history)\n",
    "    return max_grad - min_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0461f",
   "metadata": {},
   "source": [
    "We visualise the change in gradients for a specific attention head, and compare it to the shape of its output. We also check that the gradients range makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a266b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_attn_interpolated_outputs(target_layer_num=11, target_pos=10)\n",
    "\n",
    "alphas, grad_history_1110 = attn_interpolated_gradients(target_layer_num=11, target_pos=10)\n",
    "\n",
    "mean_grad_history_1110 = mean_attribution(grad_history_1110) # Shape (n_steps, 1)\n",
    "\n",
    "plt.title(f\"Mean gradient of output wrt interpolated inputs (head 11.10)\")\n",
    "plt.plot(alphas, [grad.item() for grad in mean_grad_history_1110])\n",
    "plt.xlabel(\"Interpolation coefficient\")\n",
    "plt.ylabel(\"Gradient of output wrt input at head\")\n",
    "plt.show()\n",
    "\n",
    "print(quantify_gradients_range(mean_grad_history_1110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_attn_interpolated_outputs(target_layer_num=9, target_pos=6)\n",
    "\n",
    "alphas, grad_history_96 = attn_interpolated_gradients(target_layer_num=9, target_pos=6)\n",
    "\n",
    "mean_grad_history_96 = mean_attribution(grad_history_96) # Shape (n_steps, 1)\n",
    "\n",
    "plt.title(f\"Mean gradient of output wrt interpolated inputs (head 9.6)\")\n",
    "plt.plot(alphas, [grad.item() for grad in mean_grad_history_96])\n",
    "plt.xlabel(\"Interpolation coefficient\")\n",
    "plt.ylabel(\"Gradient of output wrt input at head\")\n",
    "plt.show()\n",
    "\n",
    "print(quantify_gradients_range(mean_grad_history_96))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05fb75",
   "metadata": {},
   "source": [
    "### Correlation between gradients range and activation patching scores\n",
    "\n",
    "We quantify the range in gradients across all attention heads, and compare it to the activation patching score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_grad_ranges = torch.zeros((model.cfg.n_layers, model.cfg.n_heads))\n",
    "\n",
    "for layer_num in model.cfg.n_layers:\n",
    "    for head_pos in model.cfg.n_heads:\n",
    "        alphas, grad_history = attn_interpolated_gradients(layer_num, head_pos)\n",
    "        mean_grad_history = mean_attribution(grad_history)\n",
    "        grad_range = quantify_gradients_range(mean_grad_history)\n",
    "        attn_grad_ranges[layer_num, head_pos] = grad_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b47c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_patch_results = torch.load(\"attn_patch_results.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gradient ranges and activation patching scores side-by-side\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Gradient ranges for attention heads\")\n",
    "plt.imshow(attn_grad_ranges.detach(), cmap=\"RdBu\")\n",
    "plt.xlabel(\"Head Index\")\n",
    "plt.xticks(list(range(model.cfg.n_heads)))\n",
    "plt.ylabel(\"Layer\")\n",
    "plt.yticks(list(range(model.cfg.n_layers)))\n",
    "plt.colorbar(orientation=\"horizontal\")\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Activation patching scores for attention heads\")\n",
    "plt.imshow(attn_patch_results.detach(), cmap=\"RdBu\")\n",
    "plt.xlabel(\"Head Index\")\n",
    "plt.xticks(list(range(model.cfg.n_heads)))\n",
    "plt.ylabel(\"Layer\")\n",
    "plt.yticks(list(range(model.cfg.n_layers)))\n",
    "plt.colorbar(orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c05eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation between gradient range and activation patching score\n",
    "\n",
    "attn_grad_ranges_1d = attn_grad_ranges.flatten()\n",
    "attn_patch_results_1d = attn_patch_results.flatten()\n",
    "\n",
    "sns.regplot(x=attn_grad_ranges_1d, y=attn_patch_results_1d)\n",
    "plt.xlabel(\"Range in gradient of output wrt interpolated inputs\")\n",
    "plt.ylabel(\"Activation patching attribution scores\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Correlation coefficient between gradient range and activation patching score: {np.corrcoef(attn_grad_ranges_1d, attn_patch_results_1d)[0, 1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
