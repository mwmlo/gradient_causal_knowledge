{
 "cells": [
  {
   "cell_type": "raw",
   "id": "581fbc13",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Testing for AND/OR circuits in GPT2-Small\"\n",
    "format:\n",
    "    html:\n",
    "        code-fold: true\n",
    "        toc: true\n",
    "        toc-location: left\n",
    "        embed-resources: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ef359",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "- Hypothesis: another explanation for discrepancies is that integrated gradients may flag latent components (which only activate in AND/OR circuits). For example, a later attention head may depend on an earlier one.\n",
    "- Method: we run activation patching from corrupt to clean, and from clean to corrupt. We also run integrated gradients from corrupt to clean, and from clean to corrupt. AND/OR components will be flagged in integrated gradients in both directions, but only flagged in one direction for patching.\n",
    "    - Clean→corrupt should pick up OR circuits, Corrupt→clean should pick up AND circuits.\n",
    "    - AP asymmetry score: difference between AP scores in two directions, normalised by max score.\n",
    "    - IG asymmetry score: difference between IG scores in two directions, normalised by max score.\n",
    "    - AND/OR candidates should have low IG asymmetry and high AP asymmetry.\n",
    "\n",
    "- Implications: if true, we could use IG to detect results which would have required two activation patching passes in different directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be4e0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/mwl21/fypvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from typing import Optional\n",
    "\n",
    "from transformer_lens.utils import get_act_name, get_device\n",
    "from transformer_lens import ActivationCache, HookedTransformer, HookedTransformerConfig\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import Task, TaskDataset, logit_diff_metric, run_from_layer_fn, plot_attn_comparison, plot_correlation\n",
    "from split_ig import SplitLayerIntegratedGradients\n",
    "from attribution_methods import integrated_gradients, activation_patching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2954dc9",
   "metadata": {},
   "source": [
    "# AND/OR toy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "class ANDORNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANDORNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def run_with_cache(self, x):\n",
    "        cache = {}\n",
    "\n",
    "        # Hook function to save output\n",
    "        def save_activation(name):\n",
    "            def hook(module, input, output):\n",
    "                cache[name] = output.detach()\n",
    "            return hook\n",
    "\n",
    "        # Register hooks\n",
    "        handles = []\n",
    "        for idx, layer in enumerate(self.model):\n",
    "            handles.append(layer.register_forward_hook(save_activation(f\"layer_{idx}\")))\n",
    "\n",
    "        # Run forward pass\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(x)\n",
    "\n",
    "        # Clean up hooks\n",
    "        for handle in handles:\n",
    "            handle.remove()\n",
    "\n",
    "        return output, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data for AND logic gate\n",
    "X = torch.tensor([[0., 0.],\n",
    "                  [0., 1.],\n",
    "                  [1., 0.],\n",
    "                  [1., 1.]])\n",
    "\n",
    "y = torch.tensor([[0.],\n",
    "                  [0.],\n",
    "                  [0.],\n",
    "                  [1.]])\n",
    "\n",
    "\n",
    "# Initialize the network, loss function and optimizer\n",
    "and_model = ANDORNet()\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy for binary classification\n",
    "optimizer = optim.SGD(and_model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = and_model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate model\n",
    "with torch.no_grad():\n",
    "    preds = and_model(X)\n",
    "    print(\"Predictions:\")\n",
    "    print(preds.round())  # Round predictions to get binary output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Training data for OR logic gate\n",
    "X = torch.tensor([[0., 0.],\n",
    "                  [0., 1.],\n",
    "                  [1., 0.],\n",
    "                  [1., 1.]])\n",
    "\n",
    "y = torch.tensor([[0.],\n",
    "                  [1.],\n",
    "                  [1.],\n",
    "                  [1.]])\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "or_model = ANDORNet()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(or_model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = or_model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    preds = or_model(X)\n",
    "    print(\"Predictions:\")\n",
    "    print(preds.round())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5feb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0528937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "def simple_integrated_gradients(model: nn.Module, inputs, baseline_cache, patching_cache):\n",
    "    n_samples = inputs.size(0)\n",
    "    results = torch.zeros(n_samples, 3) # Neurons A, B, C\n",
    "\n",
    "    def make_patching_hook(patch_value):\n",
    "        def hook(module, input, output):\n",
    "            return patch_value\n",
    "        return hook\n",
    "    \n",
    "    def run_from_layer(input, layer_idx, patch_value):\n",
    "        hook_handle = model.model[layer_idx].register_forward_hook(make_patching_hook(patch_value))\n",
    "        with torch.no_grad():\n",
    "            patched_output = model(input)\n",
    "        return patched_output\n",
    "    \n",
    "    for idx, layer in enumerate(model.model):\n",
    "        forward_fn = lambda x: run_from_layer(inputs, idx, x)\n",
    "        ig = LayerIntegratedGradients(forward_fn, layer, multiply_by_inputs=True)\n",
    "\n",
    "        patch_value = patching_cache[f\"layer_{idx}\"]\n",
    "        baseline_value = baseline_cache[f\"layer_{idx}\"]\n",
    "        layer_attributions = ig.attribute(inputs=patch_value, baselines=baseline_value, internal_batch_size=n_samples)\n",
    "        results[:, idx] = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55197f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31b2c997",
   "metadata": {},
   "source": [
    "# AND/OR circuits in GPT2-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb8892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = get_device()\n",
    "# device = torch.device(\"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# Explicitly calculate and expose the result for each attention head\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df11bf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean logit difference: tensor([-0.0307, -0.9269, -0.4937,  2.2320,  0.6754,  4.0447, -0.1785,  1.1947,\n",
      "         1.1514,  1.7507], device='cuda:0')\n",
      "Corrupted logit difference: tensor([-0.0387, -0.9451, -0.5103,  2.2153,  0.6299, -3.2074, -0.1823,  1.1766,\n",
      "        -3.0072,  1.7392], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ioi_dataset = TaskDataset(Task.IOI)\n",
    "ioi_dataloader = ioi_dataset.to_dataloader(batch_size=10)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(ioi_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e39ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error (delta) for blocks.0.attn.hook_result attribution: tensor([-1.4020e-06,  4.9733e-07,  1.5763e-06, -1.4198e-06,  4.1211e-07,\n",
      "        -2.5690e-05,  2.8592e-07,  6.0722e-07,  1.3560e-05,  2.9227e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.0.mlp.hook_post attribution: tensor([-2.5807e-06, -1.2219e-06, -4.9546e-07, -7.9628e-07,  8.7917e-07,\n",
      "        -2.3365e-05, -5.2527e-07,  1.2442e-06,  1.6928e-05,  3.0734e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.1.attn.hook_result attribution: tensor([-6.7381e-07, -1.3532e-06, -7.0618e-07,  3.7951e-07, -3.1944e-06,\n",
      "        -2.9422e-05, -4.0187e-07,  1.3728e-06,  1.1683e-05, -4.5705e-07],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.1.mlp.hook_post attribution: tensor([-1.3824e-06, -2.1905e-06, -1.1295e-06, -9.3598e-07,  3.1888e-06,\n",
      "        -1.0759e-05,  9.0152e-07,  2.5430e-06,  6.3032e-06,  4.2841e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.2.attn.hook_result attribution: tensor([-2.6787e-07, -4.5029e-07, -2.9149e-06,  8.6264e-07,  3.9067e-06,\n",
      "         6.6310e-06, -1.6466e-06,  2.7753e-06,  5.0478e-06,  9.4197e-07],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.2.mlp.hook_post attribution: tensor([-1.8575e-06, -3.1129e-06, -8.8452e-07, -2.2687e-06, -5.6811e-08,\n",
      "        -1.9372e-05, -1.4792e-06,  7.4808e-07,  3.8147e-06,  2.0672e-06],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.3.attn.hook_result attribution: tensor([-1.1390e-06,  1.7136e-07, -1.1194e-06, -1.0580e-06, -1.4235e-06,\n",
      "        -1.8626e-05, -6.4448e-07,  1.1921e-06,  2.2769e-05,  2.1420e-08],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.3.mlp.hook_post attribution: tensor([-1.8766e-06, -1.1794e-06,  2.2259e-07, -1.7649e-07,  3.1386e-07,\n",
      "        -7.8380e-06,  2.4214e-07,  2.9244e-07,  5.9754e-06,  5.6019e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.4.attn.hook_result attribution: tensor([-1.7844e-06, -1.5006e-06,  7.0315e-07, -7.8767e-07,  1.7728e-06,\n",
      "        -1.5505e-05, -1.8924e-06,  1.2449e-06,  8.8662e-06,  1.8636e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.4.mlp.hook_post attribution: tensor([-9.8371e-07, -1.6303e-06, -1.9663e-06, -6.0489e-07,  2.3474e-06,\n",
      "        -5.5134e-06, -2.3488e-06,  1.9302e-06,  1.3411e-05,  5.1642e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.5.attn.hook_result attribution: tensor([ 8.3819e-09, -9.2387e-07, -4.4703e-08,  3.6322e-07,  1.6876e-06,\n",
      "        -1.0312e-05, -7.9907e-07,  1.4901e-06, -2.3842e-06, -1.0030e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.5.mlp.hook_post attribution: tensor([-5.9931e-07, -9.1514e-07, -8.6147e-08, -2.1430e-06, -6.8266e-07,\n",
      "        -1.7107e-05, -1.5441e-06,  1.9743e-06,  2.8759e-06, -5.9232e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.6.attn.hook_result attribution: tensor([-1.9926e-06, -1.8887e-06,  1.0615e-06, -2.6722e-06,  1.3262e-06,\n",
      "        -3.6210e-06,  5.0687e-07,  2.5153e-06,  6.2585e-07,  2.3211e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.6.mlp.hook_post attribution: tensor([-1.2447e-06, -1.5702e-06, -3.6089e-07,  2.9977e-07,  6.1654e-07,\n",
      "        -1.0759e-05, -2.0489e-06,  1.3239e-06,  1.8686e-05,  1.7243e-06],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.7.attn.hook_result attribution: tensor([-5.0775e-07, -2.4401e-06, -1.3690e-07, -6.3796e-07,  2.3283e-07,\n",
      "        -6.5565e-07, -1.2219e-06,  2.4084e-06,  3.5763e-07,  2.2631e-07],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.7.mlp.hook_post attribution: tensor([-9.5647e-07, -8.7731e-07, -4.2748e-07, -2.0582e-07,  3.7579e-07,\n",
      "        -8.2999e-06, -1.7229e-08,  7.7626e-07,  2.9802e-07,  3.1432e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.8.attn.hook_result attribution: tensor([-2.1262e-06, -1.6261e-06,  2.8685e-07, -1.7071e-06,  2.4643e-06,\n",
      "        -2.0504e-05, -8.8476e-07,  1.0878e-06,  2.1458e-05,  1.2880e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.8.mlp.hook_post attribution: tensor([-1.2443e-06, -1.2836e-06, -2.1397e-06, -6.2329e-07,  2.1437e-06,\n",
      "        -9.1754e-06, -1.0701e-06,  1.2806e-06, -1.0878e-06,  5.5879e-09],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.9.attn.hook_result attribution: tensor([-1.1824e-06, -1.4072e-06,  5.4389e-07, -1.1718e-06, -1.8808e-06,\n",
      "        -1.2279e-05, -2.9383e-07,  1.5609e-06,  9.0599e-06,  1.5193e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.9.mlp.hook_post attribution: tensor([-1.0943e-07, -1.1735e-06, -2.6100e-07, -7.3691e-07, -7.1945e-08,\n",
      "        -2.8610e-06, -1.7821e-06,  4.2608e-07, -1.8775e-06,  7.6357e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.10.attn.hook_result attribution: tensor([-7.4692e-07, -2.5332e-06,  1.8673e-07, -4.7404e-07,  2.1271e-06,\n",
      "        -3.1471e-05, -1.2610e-06,  9.0199e-07, -3.7551e-06,  8.6846e-07],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.10.mlp.hook_post attribution: tensor([ 3.8056e-07, -1.5013e-06, -6.9966e-08, -5.6939e-07,  8.1607e-08,\n",
      "        -1.2591e-05, -1.7504e-06,  6.0536e-07,  1.9886e-05,  1.4661e-06],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.11.attn.hook_result attribution: tensor([-8.8359e-07, -1.1213e-06, -1.5274e-07, -3.0920e-07,  1.0841e-06,\n",
      "         9.5367e-07, -7.7393e-07,  1.7714e-06,  8.5831e-06, -1.5849e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.11.mlp.hook_post attribution: tensor([ 5.1013e-07, -1.7034e-06, -9.5431e-07, -2.2771e-07,  7.0548e-07,\n",
      "        -9.8944e-06, -8.4098e-07,  1.6503e-06,  2.3663e-05,  7.6962e-07],\n",
      "       device='cuda:0')\n",
      "Activation patching on attention heads in layer 0\n",
      "Activation patching on MLP in layer 0\n",
      "Activation patching on attention heads in layer 1\n",
      "Activation patching on MLP in layer 1\n",
      "Activation patching on attention heads in layer 2\n",
      "Activation patching on MLP in layer 2\n",
      "Activation patching on attention heads in layer 3\n",
      "Activation patching on MLP in layer 3\n",
      "Activation patching on attention heads in layer 4\n",
      "Activation patching on MLP in layer 4\n",
      "Activation patching on attention heads in layer 5\n",
      "Activation patching on MLP in layer 5\n",
      "Activation patching on attention heads in layer 6\n",
      "Activation patching on MLP in layer 6\n",
      "Activation patching on attention heads in layer 7\n",
      "Activation patching on MLP in layer 7\n",
      "Activation patching on attention heads in layer 8\n",
      "Activation patching on MLP in layer 8\n",
      "Activation patching on attention heads in layer 9\n",
      "Activation patching on MLP in layer 9\n",
      "Activation patching on attention heads in layer 10\n",
      "Activation patching on MLP in layer 10\n",
      "Activation patching on attention heads in layer 11\n",
      "Activation patching on MLP in layer 11\n"
     ]
    }
   ],
   "source": [
    "# Patch from clean to corrupt\n",
    "\n",
    "ig_clean_corrupt_mlp, ig_clean_corrupt_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, logit_diff_metric, labels)\n",
    "ap_clean_corrupt_mlp, ap_clean_corrupt_attn = activation_patching(model, clean_tokens, clean_cache, clean_logit_diff, corrupted_cache, corrupted_logit_diff, logit_diff_metric, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b615479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_clean_corrupt_mlp = torch.save(ig_clean_corrupt_mlp, \"saved_results/ig_clean_corrupt_mlp.pt\")\n",
    "ig_clean_corrupt_attn = torch.save(ig_clean_corrupt_attn, \"saved_results/ig_clean_corrupt_attn.pt\")\n",
    "ap_clean_corrupt_mlp = torch.save(ap_clean_corrupt_mlp, \"saved_results/ap_clean_corrupt_mlp.pt\")\n",
    "ap_clean_corrupt_attn = torch.save(ap_clean_corrupt_attn, \"saved_results/ap_clean_corrupt_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb8babd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error (delta) for blocks.0.attn.hook_result attribution: tensor([-2.8906e-07, -2.9011e-07,  8.9733e-07, -8.2795e-07, -1.2587e-06,\n",
      "        -2.0266e-06, -3.3854e-07,  5.1875e-07, -1.4976e-06,  6.5146e-07],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.0.mlp.hook_post attribution: tensor([-1.3113e-06, -1.7695e-07, -5.3085e-07, -3.6415e-06,  2.6822e-07,\n",
      "        -4.7684e-06, -3.5390e-07, -1.1399e-06,  4.7684e-06, -1.7341e-06],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.1.attn.hook_result attribution: tensor([ 8.1258e-08, -1.3346e-06,  1.1593e-06,  3.9861e-07, -2.5816e-06,\n",
      "         3.5120e-06, -2.3097e-07, -8.7428e-07,  4.7833e-06,  7.4506e-09],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.1.mlp.hook_post attribution: tensor([-9.4093e-07,  1.0189e-06,  3.6601e-07, -7.4413e-07,  1.9632e-06,\n",
      "         7.9051e-06, -2.4661e-06,  1.3015e-07,  5.9232e-06, -1.2573e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.2.attn.hook_result attribution: tensor([-2.1933e-07, -6.1491e-07,  1.9826e-06, -1.6543e-06,  1.5839e-06,\n",
      "         5.3346e-06, -1.7476e-06,  1.3318e-07, -4.8988e-07, -2.1637e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.2.mlp.hook_post attribution: tensor([ 1.0687e-07, -1.8054e-06,  1.5851e-06, -1.4682e-06,  2.0312e-06,\n",
      "         1.0520e-05, -7.3970e-07, -2.1653e-07,  9.0599e-06, -3.2468e-06],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.3.attn.hook_result attribution: tensor([-3.1786e-06,  4.9919e-07,  9.0525e-07, -5.4576e-07,  3.8650e-08,\n",
      "        -2.8610e-06, -2.6673e-06, -4.9081e-07,  3.2783e-06, -5.6229e-07],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.3.mlp.hook_post attribution: tensor([ 2.8289e-07, -1.1474e-06,  4.4645e-07, -1.2630e-06, -7.4180e-07,\n",
      "         6.9141e-06,  2.2198e-06, -7.0501e-07, -5.6028e-06, -1.9227e-06],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.4.attn.hook_result attribution: tensor([ 3.5763e-07,  1.3970e-09,  1.9851e-06, -6.5099e-07, -4.5635e-07,\n",
      "        -2.2352e-06, -1.4575e-06, -1.0519e-06, -1.8105e-06,  6.5006e-07],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.4.mlp.hook_post attribution: tensor([-4.2794e-07, -5.5879e-09,  4.7637e-07, -2.2324e-06,  2.2666e-06,\n",
      "         2.0653e-05, -1.1303e-06, -1.4035e-06, -5.4836e-06, -2.9895e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.5.attn.hook_result attribution: tensor([-4.8615e-07,  8.2701e-07,  3.9861e-07, -2.0647e-06, -6.7428e-07,\n",
      "        -1.4067e-05, -4.2841e-07, -1.4566e-06,  1.3709e-05, -1.1371e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.5.mlp.hook_post attribution: tensor([-9.6625e-07, -6.5332e-07, -1.2703e-06,  7.7533e-07,  3.4820e-07,\n",
      "        -6.1989e-06, -1.0431e-06,  7.2946e-07,  3.6061e-06, -1.7097e-06],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.6.attn.hook_result attribution: tensor([-8.0373e-07, -1.5674e-06,  7.2597e-07,  1.2433e-07,  6.7009e-07,\n",
      "         1.7881e-06, -2.7688e-06, -1.0622e-06,  9.1195e-06, -1.6701e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.6.mlp.hook_post attribution: tensor([-3.3819e-07, -4.1910e-07,  1.1874e-06, -2.6496e-07, -4.6147e-07,\n",
      "         9.7454e-06,  3.7439e-07,  5.1130e-07,  9.5218e-06, -1.8254e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.7.attn.hook_result attribution: tensor([-2.8324e-07, -3.5018e-07, -9.0199e-07, -9.1223e-07,  5.9884e-07,\n",
      "         1.5736e-05, -1.5739e-06, -1.9963e-06,  5.0068e-06,  2.5714e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.7.mlp.hook_post attribution: tensor([-1.7215e-06, -5.6764e-07,  2.4401e-07,  3.3528e-07, -1.9604e-07,\n",
      "         4.7088e-06, -5.5856e-07, -3.8394e-07,  1.2010e-05,  1.2452e-06],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.8.attn.hook_result attribution: tensor([-7.8697e-08, -3.3528e-07,  6.3237e-07, -1.6391e-07,  8.2143e-07,\n",
      "        -9.5367e-07, -5.2806e-07, -4.0978e-07, -7.6294e-06, -6.4494e-07],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.8.mlp.hook_post attribution: tensor([-2.4750e-07,  2.9802e-08,  1.2517e-06,  2.3800e-06, -1.1807e-06,\n",
      "         2.3544e-06, -1.7327e-06, -1.2921e-06,  1.1206e-05, -1.1600e-06],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.9.attn.hook_result attribution: tensor([-2.4169e-06, -2.1188e-07,  7.7812e-07, -1.0235e-06,  1.5697e-06,\n",
      "        -2.2650e-06,  1.6005e-06,  3.5705e-07, -5.2974e-06,  1.8720e-07],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.9.mlp.hook_post attribution: tensor([ 1.3796e-06, -5.8953e-07,  1.2508e-06, -1.9134e-06, -2.3260e-07,\n",
      "        -2.0266e-06, -1.7360e-06, -1.2952e-06, -2.1383e-06, -6.3737e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.10.attn.hook_result attribution: tensor([-8.3493e-07, -1.4901e-07, -1.5963e-06, -1.4510e-06, -2.0461e-06,\n",
      "        -1.1921e-06, -3.7253e-08, -5.7928e-07,  6.4969e-06, -1.6773e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.10.mlp.hook_post attribution: tensor([ 1.1548e-07,  1.0934e-06,  2.0070e-07, -1.4983e-06,  1.0510e-06,\n",
      "         7.9125e-06, -1.5236e-06, -1.1995e-06, -9.8795e-06, -6.3208e-07],\n",
      "       device='cuda:0')\n",
      "\n",
      "Error (delta) for blocks.11.attn.hook_result attribution: tensor([ 7.0618e-07, -1.2312e-06, -4.3586e-07, -4.7730e-08, -5.4576e-07,\n",
      "         6.6757e-06, -9.6438e-07, -4.5635e-07, -4.2915e-06, -1.6955e-06],\n",
      "       device='cuda:0')\n",
      "torch.Size([10, 21, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.11.mlp.hook_post attribution: tensor([-2.8842e-07,  2.9523e-07,  1.3504e-07,  1.4110e-06, -6.0815e-07,\n",
      "         1.7881e-06, -1.9353e-06, -7.5833e-07,  3.4645e-07, -3.5029e-07],\n",
      "       device='cuda:0')\n",
      "Activation patching on attention heads in layer 0\n",
      "Activation patching on MLP in layer 0\n",
      "Activation patching on attention heads in layer 1\n",
      "Activation patching on MLP in layer 1\n",
      "Activation patching on attention heads in layer 2\n",
      "Activation patching on MLP in layer 2\n",
      "Activation patching on attention heads in layer 3\n",
      "Activation patching on MLP in layer 3\n",
      "Activation patching on attention heads in layer 4\n",
      "Activation patching on MLP in layer 4\n",
      "Activation patching on attention heads in layer 5\n",
      "Activation patching on MLP in layer 5\n",
      "Activation patching on attention heads in layer 6\n",
      "Activation patching on MLP in layer 6\n",
      "Activation patching on attention heads in layer 7\n",
      "Activation patching on MLP in layer 7\n",
      "Activation patching on attention heads in layer 8\n",
      "Activation patching on MLP in layer 8\n",
      "Activation patching on attention heads in layer 9\n",
      "Activation patching on MLP in layer 9\n",
      "Activation patching on attention heads in layer 10\n",
      "Activation patching on MLP in layer 10\n",
      "Activation patching on attention heads in layer 11\n",
      "Activation patching on MLP in layer 11\n"
     ]
    }
   ],
   "source": [
    "# Patch from corrupt to clean\n",
    "\n",
    "ig_corrupt_clean_mlp, ig_corrupt_clean_attn = integrated_gradients(model, corrupted_tokens, corrupted_cache, clean_cache, logit_diff_metric, labels)\n",
    "ap_corrupt_clean_mlp, ap_corrupt_clean_attn = activation_patching(model, corrupted_tokens, corrupted_cache, corrupted_logit_diff, clean_cache, clean_logit_diff, logit_diff_metric, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "164631d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_corrupt_clean_mlp = torch.save(ig_corrupt_clean_mlp, \"saved_results/ig_corrupt_clean_mlp.pt\")\n",
    "ig_corrupt_clean_attn = torch.save(ig_corrupt_clean_attn, \"saved_results/ig_corrupt_clean_attn.pt\")\n",
    "ap_corrupt_clean_mlp = torch.save(ap_corrupt_clean_mlp, \"saved_results/ap_corrupt_clean_mlp.pt\")\n",
    "ap_corrupt_clean_attn = torch.save(ap_corrupt_clean_attn, \"saved_results/ap_corrupt_clean_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetry_score(corrupt_clean: torch.Tensor, clean_corrupt: torch.Tensor):\n",
    "    assert corrupt_clean.shape == clean_corrupt.shape, \\\n",
    "        f\"Cannot calculate asymmetry between matrices of different shapes, {corrupt_clean.shape} and {clean_corrupt.shape}\"\n",
    "    max_score = max(corrupt_clean.max(), clean_corrupt.max())\n",
    "    return (corrupt_clean - clean_corrupt).abs() / max_score\n",
    "\n",
    "ig_mlp_asymmetry = asymmetry_score(ig_corrupt_clean_mlp, ig_clean_corrupt_mlp)\n",
    "ig_attn_asymmetry = asymmetry_score(ig_corrupt_clean_attn, ig_clean_corrupt_attn)\n",
    "\n",
    "ap_mlp_asymmetry = asymmetry_score(ap_corrupt_clean_mlp, ap_clean_corrupt_mlp)\n",
    "ap_attn_asymmetry = asymmetry_score(ap_corrupt_clean_attn, ap_clean_corrupt_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0569bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_attn\n",
    "\n",
    "plot_attn(ig_attn_asymmetry, model)\n",
    "plot_attn(ap_attn_asymmetry, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
