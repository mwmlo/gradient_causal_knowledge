{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3b765c",
   "metadata": {},
   "source": [
    "# Analysis of disagreements\n",
    "\n",
    "In this series of experiments, we use ablation studies to investigate the role of components highlighted by either Integrated Gradients or activation patching, but not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac47a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device, get_act_name\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from attribution_methods import integrated_gradients, activation_patching, highlight_components\n",
    "from testing import Task, TaskDataset, logit_diff_metric, identify_outliers, average_correlation, measure_overlap, test_single_ablated_performance, test_multi_ablated_performance\n",
    "from plotting import plot_attn, plot_attn_comparison, plot_correlation, plot_correlation_comparison, plot_bar_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b120b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = get_device()\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# Explicitly calculate and expose the result for each attention head\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daec5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure baseline performance\n",
    "\n",
    "test_dataset = TaskDataset(Task.IOI)\n",
    "test_dataloader = test_dataset.to_dataloader(batch_size=10)\n",
    "\n",
    "baseline_scores = []\n",
    "\n",
    "for i, (clean_input, _, labels) in enumerate(test_dataloader):\n",
    "    clean_tokens = model.to_tokens(clean_input)\n",
    "    logits = model(clean_tokens)\n",
    "    baseline_scores.append(logit_diff_metric(logits, labels))\n",
    "\n",
    "baseline_performance = sum(baseline_scores) / len(baseline_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_mlp = torch.load(\"results/aligned/ioi/ig_mlp.pt\")\n",
    "ig_attn = torch.load(\"results/aligned/ioi/ig_attn.pt\")\n",
    "\n",
    "ap_mlp = torch.load(\"results/aligned/ioi/ap_mlp.pt\")\n",
    "ap_attn = torch.load(\"results/aligned/ioi/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c565828",
   "metadata": {},
   "source": [
    "## Identify disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify statistically significant outlier components\n",
    "\n",
    "scaled_ig_attn = ig_attn * 1e5\n",
    "attn_outliers = identify_outliers(scaled_ig_attn, ap_attn)\n",
    "mlp_outliers = identify_outliers(ig_mlp, ap_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean activations over a corrupt dataset\n",
    "\n",
    "attn_outlier_hooks = [get_act_name(\"result\", layer_idx) for layer_idx, _ in attn_outliers]\n",
    "mlp_outlier_hooks = [get_act_name(\"post\", layer_idx) for layer_idx, _ in mlp_outliers]\n",
    "\n",
    "random_prompts = random.sample(test_dataset, 100)\n",
    "prompts_tokens = model.to_tokens([p for p, _ in random_prompts])\n",
    "_, prompt_cache = model.run_with_cache(\n",
    "    prompts_tokens, \n",
    "    names_filter=lambda x: x in attn_outlier_hooks or x in mlp_outlier_hooks\n",
    ")\n",
    "\n",
    "mean_corrupt_activations = {}\n",
    "for key in prompt_cache.keys():\n",
    "    mean_values_over_prompts = torch.mean(prompt_cache[key], dim=0)\n",
    "    mean_corrupt_activations[key] = torch.mean(mean_values_over_prompts, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c443d00",
   "metadata": {},
   "source": [
    "## Performance under isolated ablation\n",
    "\n",
    "- Hypothesis: components which have high attribution scores in only one of the two methods are still important.\n",
    "- Method: we measure the performance of a GPT2-small model when the components which are exclusive to only one method are ablated (with mean corrupt activations), one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d4959",
   "metadata": {},
   "source": [
    "### Attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccaa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_outlier_isolated_ablation_scores = dict()\n",
    "\n",
    "for layer, idx in attn_outliers:\n",
    "    score = test_single_ablated_performance(model, layer, idx, mean_corrupt_activations, Task.IOI, is_attn=True)\n",
    "    attn_outlier_isolated_ablation_scores[(layer, idx)] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Model performance after isolated ablation of attention head outliers\")\n",
    "plt.xlabel(\"Ablated attention head position\")\n",
    "plt.ylabel(\"Model performance on IOI task\")\n",
    "\n",
    "xs = [\"None\"] + [str(t) for t in attn_outlier_isolated_ablation_scores.keys()]\n",
    "ys = [baseline_performance] + attn_outlier_isolated_ablation_scores.values()\n",
    "\n",
    "plt.bar(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8d323",
   "metadata": {},
   "source": [
    "### Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_outlier_isolated_ablation_scores = dict()\n",
    "\n",
    "for layer, idx in mlp_outliers:\n",
    "    score = test_single_ablated_performance(model, layer, idx, mean_corrupt_activations, Task.IOI, is_attn=False)\n",
    "    mlp_outlier_isolated_ablation_scores[(layer, idx)] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Model performance after isolated ablation of neuron outliers\")\n",
    "plt.xlabel(\"Ablated neuron position\")\n",
    "plt.ylabel(\"Model performance on IOI task\")\n",
    "\n",
    "xs = [\"None\"] + [str(t) for t in mlp_outlier_isolated_ablation_scores.keys()]\n",
    "ys = [baseline_performance] + mlp_outlier_isolated_ablation_scores.values()\n",
    "\n",
    "plt.bar(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd41030",
   "metadata": {},
   "source": [
    "## Performance under simultaneous ablation\n",
    "\n",
    "- Hypothesis: components which have high attribution scores in only one of the two methods may be involved in multi-component interactions.\n",
    "- Method: we measure the performance when the components exclusive to only one method are ablated all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e30804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablate method-exclusive components\n",
    "\n",
    "outlier_attn_multi_ablated_performance = test_multi_ablated_performance(model, attn_outliers, mean_corrupt_activations, Task.IOI, is_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablate all IG-highlighted components\n",
    "ig_attn_highlighted, ig_attn_indices = highlight_components(ig_attn)\n",
    "ig_attn_multi_ablated_performance = test_multi_ablated_performance(model, ig_attn_indices, mean_corrupt_activations, Task.IOI, is_attn=True)\n",
    "\n",
    "# Ablate all AP-highlighted components\n",
    "ap_attn_highlighted, ap_attn_indices = highlight_components(ap_attn)\n",
    "ap_attn_multi_ablated_performance = test_multi_ablated_performance(model, ap_attn_indices, mean_corrupt_activations, Task.IOI, is_attn=True)\n",
    "\n",
    "# Ablate all IG and AP highlighted components\n",
    "shared_attn_indices = (ig_attn_highlighted & ap_attn_highlighted).nonzero()\n",
    "shared_attn_multi_ablated_performance = test_multi_ablated_performance(model, shared_attn_indices, mean_corrupt_activations, Task.IOI, is_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Model performance after simultaneous ablation of attention heads\")\n",
    "plt.xlabel(\"Method(s) to highlight ablated attention heads\")\n",
    "plt.ylabel(\"Model performance on IOI task\")\n",
    "\n",
    "xs = [\"None\", \"IG\", \"AP\", \"IG + AP\", \"Exclusive\" ]\n",
    "ys = [baseline_performance, ig_attn_multi_ablated_performance, ap_attn_multi_ablated_performance, shared_attn_multi_ablated_performance, outlier_attn_multi_ablated_performance]\n",
    "\n",
    "plt.bar(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466caf49",
   "metadata": {},
   "source": [
    "### Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae3b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablate method-exclusive components\n",
    "outlier_mlp_multi_ablated_performance = test_multi_ablated_performance(model, mlp_outliers, mean_corrupt_activations, Task.IOI, is_attn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff91959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablate all IG-highlighted components\n",
    "ig_mlp_highlighted, ig_mlp_indices = highlight_components(ig_mlp)\n",
    "ig_mlp_multi_ablated_performance = test_multi_ablated_performance(model, ig_mlp_indices, mean_corrupt_activations, Task.IOI, is_attn=False)\n",
    "\n",
    "# Ablate all AP-highlighted components\n",
    "ap_mlp_highlighted, ap_mlp_indices = highlight_components(ap_mlp)\n",
    "ap_mlp_multi_ablated_performance = test_multi_ablated_performance(model, ap_mlp_indices, mean_corrupt_activations, Task.IOI, is_attn=False)\n",
    "\n",
    "# Ablate all IG and AP highlighted components\n",
    "shared_mlp_indices = (ig_mlp_highlighted & ap_mlp_highlighted).nonzero()\n",
    "shared_mlp_multi_ablated_performance = test_multi_ablated_performance(model, shared_mlp_indices, mean_corrupt_activations, Task.IOI, is_attn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Model performance after simultaneous ablation of neurons\")\n",
    "plt.xlabel(\"Method(s) to highlight ablated neurons\")\n",
    "plt.ylabel(\"Model performance on IOI task\")\n",
    "\n",
    "xs = [\"None\", \"IG\", \"AP\", \"IG + AP\", \"Exclusive\" ]\n",
    "ys = [baseline_performance, ig_mlp_multi_ablated_performance, ap_mlp_multi_ablated_performance, shared_mlp_multi_ablated_performance, outlier_mlp_multi_ablated_performance]\n",
    "\n",
    "plt.bar(xs, ys)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
