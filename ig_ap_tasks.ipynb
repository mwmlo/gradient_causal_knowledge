{
 "cells": [
  {
   "cell_type": "raw",
   "id": "40676fd2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Integrated Gradients vs Activation Patching Across Circuits\"\n",
    "format:\n",
    "    html:\n",
    "        code-fold: true\n",
    "        toc: true\n",
    "        toc-location: left\n",
    "        embed-resources: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09389a15",
   "metadata": {},
   "source": [
    "**Goal**: investigate the agreement between integrated gradients and activation patching when the baselines are similar, across a variety of circuit tasks.\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "- Indirect Object Identification (![Wang et al, 2023](https://arxiv.org/pdf/2211.00593)): consists of inputs like “When Mary and John went to the store, John gave a bottle of milk to”; models are expected to predict “Mary”. Performance measured using logit differences.\n",
    "\n",
    "- Gender-Bias (![Vig et al, 2020](https://proceedings.neurips.cc/paper/2020/hash/92650b2e92217715fe312e6fa7b90d82-Abstract.html)): designed to study gender bias in LMs. Gives models inputs like “The nurse said that”; biased models tend to complete this sentence with “she”. Performance measured using logit differences.\n",
    "\n",
    "- Greater-Than (![Hanna et al., 2023](https://arxiv.org/abs/2305.00586)): models receive input like “The war lasted from the year 1741 to the year 17”, and must predict a valid two-digit end year, i.e. one that is greater than 41. Performance measured using probability differences. \n",
    "\n",
    "- Capital–Country (![Hanna et al., 2024](https://arxiv.org/abs/2403.17806)): models receive input like “Tirana, the capital of” and must output the corresponding country (Albania). Corrupted instances contain another capital (e.g. Brasilia) instead. Performance measured using logit differences.\n",
    "\n",
    "- Subject-Verb Agreement (SVA) (![Newman et al, 2021](https://aclanthology.org/2021.naacl-main.290/)): models receive a sentence like “The keys on the cabinet”, and must output a verb that agrees in number with the subject (keys), e.g. are or have. In corrupted inputs, the subject’s number is changed, e.g. from keys to key, causing the model to output verbs of opposite agreement. Performance measured using probability differences. \n",
    "\n",
    "- Hypernymy: models must predict a word’s hypernym, or super- ordinate category, given inputs like “diamonds, and other”; the correct answer is “gems” or “gemstones”. Corrupted inputs contain an example of a distinct category, e.g. cars, which are vehicles. Performance measured using probability differences. This task is hard for small models, so we exclude inputs where GPT2-small gets a probability difference < 0.1 (following ![Hanna et al., 2024](https://arxiv.org/abs/2403.17806))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618bf35e",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86280d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from typing import Optional\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "from transformer_lens.utils import get_act_name, get_device\n",
    "from transformer_lens import ActivationCache, HookedTransformer, HookedTransformerConfig\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffabfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Task(Enum):\n",
    "    IOI = 1\n",
    "    GENDER_BIAS = 2\n",
    "    GREATER_THAN = 3\n",
    "    CAPITAL_COUNTRY = 4\n",
    "    SVA = 5\n",
    "    HYPERNYMY = 6\n",
    "\n",
    "# Implementation of dataset loader based on https://github.com/hannamw/eap-ig-faithfulness\n",
    "\n",
    "def collate_EAP(xs, task: Task):\n",
    "    clean, corrupted, labels = zip(*xs)\n",
    "    clean = list(clean)\n",
    "    corrupted = list(corrupted)\n",
    "    if task != Task.HYPERNYMY:\n",
    "        labels = torch.tensor(labels)\n",
    "    return clean, corrupted, labels\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, task: Task):\n",
    "        filename = task.name.lower()\n",
    "        self.task = task\n",
    "        self.df = pd.read_csv(f'datasets/{filename}.csv')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1)\n",
    "\n",
    "    def head(self, n: int):\n",
    "        self.df = self.df.head(n)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        label = None\n",
    "\n",
    "        if self.task == Task.IOI:\n",
    "            label = [row['correct_idx'], row['incorrect_idx']]\n",
    "            return row['clean'], row['corrupted_hard'], label\n",
    "        \n",
    "        if self.task == Task.GREATER_THAN:\n",
    "            label = row['correct_idx']\n",
    "        elif self.task == Task.HYPERNYMY:\n",
    "            answer = torch.tensor(eval(row['answers_idx']))\n",
    "            corrupted_answer = torch.tensor(eval(row['corrupted_answers_idx']))\n",
    "            label = [answer, corrupted_answer]\n",
    "        elif self.task == Task.CAPITAL_COUNTRY:\n",
    "            label = [row['country_idx'], row['corrupted_country_idx']]\n",
    "        elif self.task == Task.GENDER_BIAS:\n",
    "            label = [row['clean_answer_idx'], row['corrupted_answer_idx']]\n",
    "        elif self.task == Task.SVA:\n",
    "            label = row['plural']\n",
    "        else:\n",
    "            raise ValueError(f'Got invalid task: {self.task}')\n",
    "        \n",
    "        return row['clean'], row['corrupted'], label\n",
    "    \n",
    "    def to_dataloader(self, batch_size: int):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=partial(collate_EAP, task=self.task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b568b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = get_device()\n",
    "# device = torch.device(\"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# Explicitly calculate and expose the result for each attention head\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72fdbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_diff_metric(logits, correct_index, incorrect_index):\n",
    "    logits_last = logits[:, -1, :]\n",
    "    batch_size = logits.size(0)\n",
    "    correct_logits = logits_last[torch.arange(batch_size), correct_index]\n",
    "    incorrect_logits = logits_last[torch.arange(batch_size), incorrect_index]\n",
    "    return correct_logits - incorrect_logits\n",
    "\n",
    "def prob_diff_metric():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ab4cb",
   "metadata": {},
   "source": [
    "## Integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7c8175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_from_layer_fn(original_input, patch_layer, patch_output, metric, correct_idx, incorrect_idx, reset_hooks_end=True):\n",
    "    def fwd_hook(act, hook):\n",
    "        assert patch_output.shape == act.shape, f\"Patch shape {patch_output.shape} doesn't match activation shape {act.shape}\"\n",
    "        return patch_output\n",
    "\n",
    "    logits = model.run_with_hooks(\n",
    "        original_input,\n",
    "        fwd_hooks=[(patch_layer.name, fwd_hook)],\n",
    "        reset_hooks_end=reset_hooks_end,\n",
    "    )\n",
    "    \n",
    "    assert logits.shape[0] == correct_idx.shape[0] == incorrect_idx.shape[0]\n",
    "    diff = metric(logits, correct_idx, incorrect_idx)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def compute_layer_to_output_attributions(original_input, layer_input, layer_baseline, target_layer, prev_layer, metric, correct_idx, incorrect_idx):\n",
    "    n_samples = original_input.size(0)\n",
    "    # Take the model starting from the target layer\n",
    "    forward_fn = lambda x: run_from_layer_fn(original_input, prev_layer, x, metric, correct_idx, incorrect_idx)\n",
    "    # Attribute to the target_layer's output\n",
    "    ig_embed = LayerIntegratedGradients(forward_fn, target_layer, multiply_by_inputs=True)\n",
    "    attributions, approximation_error = ig_embed.attribute(inputs=layer_input,\n",
    "                                                    baselines=layer_baseline, \n",
    "                                                    internal_batch_size=n_samples,\n",
    "                                                    attribute_to_layer_input=False,\n",
    "                                                    return_convergence_delta=True)\n",
    "    print(f\"\\nError (delta) for {target_layer.name} attribution: {approximation_error}\")\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c0c1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_gradients(model: HookedTransformer, clean_tokens: torch.Tensor, clean_cache: ActivationCache, corrupted_cache: ActivationCache, metric: callable, correct_idx, incorrect_idx):\n",
    "    n_samples = clean_tokens.size(0)\n",
    "    \n",
    "    # Gradient attribution for neurons in MLP layers\n",
    "    mlp_results = torch.zeros(n_samples, model.cfg.n_layers, model.cfg.d_mlp)\n",
    "    # Gradient attribution for attention heads\n",
    "    attn_results = torch.zeros(n_samples, model.cfg.n_layers, model.cfg.n_heads)\n",
    "\n",
    "    # Calculate integrated gradients for each layer\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "\n",
    "        # Gradient attribution on heads\n",
    "        hook_name = get_act_name(\"result\", layer)\n",
    "        target_layer = model.hook_dict[hook_name]\n",
    "        prev_layer_hook = get_act_name(\"z\", layer)\n",
    "        prev_layer = model.hook_dict[prev_layer_hook]\n",
    "\n",
    "        layer_clean_input = clean_cache[prev_layer_hook]\n",
    "        layer_corrupt_input = corrupted_cache[prev_layer_hook]\n",
    "\n",
    "        # Shape [batch, seq_len, d_head, d_model]\n",
    "        attributions = compute_layer_to_output_attributions(\n",
    "            clean_tokens, layer_corrupt_input, layer_clean_input, target_layer, prev_layer, metric, correct_idx, incorrect_idx)\n",
    "        print(attributions.shape)\n",
    "        # Calculate attribution score based on mean over each embedding, for each token\n",
    "        per_token_score = attributions.mean(dim=3)\n",
    "        score = per_token_score.mean(dim=1)\n",
    "        attn_results[:, layer] = score\n",
    "\n",
    "        # Gradient attribution on MLP neurons\n",
    "        hook_name = get_act_name(\"post\", layer)\n",
    "        target_layer = model.hook_dict[hook_name]\n",
    "        prev_layer_hook = get_act_name(\"mlp_in\", layer)\n",
    "        prev_layer = model.hook_dict[prev_layer_hook]\n",
    "\n",
    "        layer_clean_input = clean_cache[prev_layer_hook]\n",
    "        layer_corrupt_input = corrupted_cache[prev_layer_hook]\n",
    "        \n",
    "        # Shape [batch, seq_len, d_model]\n",
    "        attributions = compute_layer_to_output_attributions(\n",
    "            clean_tokens, layer_corrupt_input, layer_clean_input, target_layer, prev_layer, metric, correct_idx, incorrect_idx)\n",
    "        score = attributions.mean(dim=1)\n",
    "        mlp_results[:, layer] = score\n",
    "\n",
    "    return mlp_results, attn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916596a0",
   "metadata": {},
   "source": [
    "## Activation patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93b786cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_hook(activations: torch.Tensor, hook: HookPoint, cache: ActivationCache, idx: int):\n",
    "    # Replace the activations for the target neuron with activations from the cached run.\n",
    "    cached_activations = cache[hook.name]\n",
    "    activations[:, :, idx] = cached_activations[:, :, idx]\n",
    "    return activations\n",
    "\n",
    "def activation_patching(model: HookedTransformer, clean_tokens: torch.Tensor, clean_cache: ActivationCache, clean_logit_diff, corrupted_cache: ActivationCache, corrupted_logit_diff, metric: callable, correct_idx, incorrect_idx):\n",
    "    n_samples = clean_tokens.size(0)\n",
    "    \n",
    "    mlp_results = torch.zeros(n_samples, model.cfg.n_layers, model.cfg.d_mlp)\n",
    "    attn_results = torch.zeros(n_samples, model.cfg.n_layers, model.cfg.n_heads)\n",
    "\n",
    "    baseline_diff = clean_logit_diff - corrupted_logit_diff\n",
    "\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        # Activation patching on heads\n",
    "        print(f\"Activation patching on attention heads in layer {layer}\")\n",
    "        for head in range(model.cfg.n_heads):\n",
    "            hook_name = get_act_name(\"result\", layer)\n",
    "            temp_hook = lambda act, hook: patch_hook(act, hook, corrupted_cache, head)\n",
    "\n",
    "            with model.hooks(fwd_hooks=[(hook_name, temp_hook)]):\n",
    "                patched_logits = model(clean_tokens)\n",
    "\n",
    "            patched_logit_diff = metric(patched_logits, correct_idx, incorrect_idx).detach()\n",
    "            # Normalise result by clean and corrupted logit difference\n",
    "            attn_results[:, layer, head] = (patched_logit_diff - clean_logit_diff) / baseline_diff\n",
    "\n",
    "        # Activation patching on MLP neurons\n",
    "        print(f\"Activation patching on MLP in layer {layer}\")\n",
    "        for neuron in range(model.cfg.d_mlp):\n",
    "            hook_name = get_act_name(\"post\", layer)\n",
    "            temp_hook = lambda act, hook: patch_hook(act, hook, corrupted_cache, neuron)\n",
    "            \n",
    "            with model.hooks(fwd_hooks=[(hook_name, temp_hook)]):\n",
    "                patched_logits = model(clean_tokens)\n",
    "\n",
    "            patched_logit_diff = metric(patched_logits, correct_idx, incorrect_idx).detach()\n",
    "            # Normalise result by clean and corrupted logit difference\n",
    "            mlp_results[:, layer, neuron] = (patched_logit_diff - clean_logit_diff) / baseline_diff\n",
    "\n",
    "    return mlp_results, attn_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97643969",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1710bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "def plot_correlation(ig_scores, ap_scores, title=None):\n",
    "    x = ig_scores.flatten()\n",
    "    y = ap_scores.flatten()\n",
    "\n",
    "    sns.regplot(x, y)\n",
    "    plt.xlabel(\"Integrated Gradients Attribution Scores\")\n",
    "    plt.ylabel(\"Activation Patching Attribution Scores\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Correlation coefficient: {np.corrcoef(x, y)[0, 1]}\")\n",
    "\n",
    "def plot_mean_diff(ig_scores, ap_scores, title=None):\n",
    "\n",
    "    x = ig_scores.flatten().numpy()\n",
    "    y = ap_scores.flatten().numpy()\n",
    "\n",
    "    # Mean difference plot with scaled data\n",
    "\n",
    "    scaled_ig_scores = MaxAbsScaler().fit_transform(x.reshape(-1, 1))\n",
    "    scaled_ap_scores = MaxAbsScaler().fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "    mean = np.mean([scaled_ig_scores, scaled_ap_scores], axis=0)\n",
    "    diff = scaled_ap_scores - scaled_ig_scores\n",
    "    md = np.mean(diff) # Mean of the difference\n",
    "    sd = np.std(diff, axis=0) # Standard deviation of the difference\n",
    "\n",
    "    sns.regplot(x=mean, y=diff, fit_reg=True, scatter=True)\n",
    "    plt.axhline(md, color='gray', linestyle='--', label=\"Mean difference\")\n",
    "    plt.axhline(md + 1.96*sd, color='pink', linestyle='--', label=\"1.96 SD of difference\")\n",
    "    plt.axhline(md - 1.96*sd, color='lightblue', linestyle='--', label=\"-1.96 SD of difference\")\n",
    "    plt.xlabel(\"Mean of attribution scores\")\n",
    "    plt.ylabel(\"Difference (activation patching - integrated gradients)\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b32209",
   "metadata": {},
   "source": [
    "# Task 1: Indirect Object Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b193685",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_dataset = TaskDataset(Task.IOI)\n",
    "ioi_dataloader = ioi_dataset.to_dataloader(batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e80e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_input, corrupted_input, labels = next(iter(ioi_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "correct_idx = labels[:, 0]\n",
    "incorrect_idx = labels[:, 1]\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, correct_idx, incorrect_idx)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, correct_idx, incorrect_idx)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b193685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error (delta) for blocks.0.attn.hook_result attribution: tensor([-9.6811e-07, -1.8389e-01], device='mps:0')\n",
      "torch.Size([2, 20, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.0.mlp.hook_post attribution: tensor([-3.5157e-07,  1.0831e+01], device='mps:0')\n",
      "\n",
      "Error (delta) for blocks.1.attn.hook_result attribution: tensor([-3.8603e-07,  2.2985e-01], device='mps:0')\n",
      "torch.Size([2, 20, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.1.mlp.hook_post attribution: tensor([2.2777e-07, 6.4581e-02], device='mps:0')\n",
      "\n",
      "Error (delta) for blocks.2.attn.hook_result attribution: tensor([-3.8603e-07, -2.6410e-01], device='mps:0')\n",
      "torch.Size([2, 20, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.2.mlp.hook_post attribution: tensor([7.6531e-07, 6.4000e-02], device='mps:0')\n",
      "\n",
      "Error (delta) for blocks.3.attn.hook_result attribution: tensor([-8.7311e-07,  4.8069e-01], device='mps:0')\n",
      "torch.Size([2, 20, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.3.mlp.hook_post attribution: tensor([1.6997e-07, 2.5395e-02], device='mps:0')\n",
      "\n",
      "Error (delta) for blocks.4.attn.hook_result attribution: tensor([ 1.5460e-07, -1.4163e-01], device='mps:0')\n",
      "torch.Size([2, 20, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.4.mlp.hook_post attribution: tensor([-2.1111e-06, -4.5471e-01], device='mps:0')\n",
      "\n",
      "Error (delta) for blocks.5.attn.hook_result attribution: tensor([-1.0747e-06,  4.1245e+00], device='mps:0')\n",
      "torch.Size([2, 20, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.5.mlp.hook_post attribution: tensor([-1.0915e-06,  1.0961e+00], device='mps:0')\n",
      "\n",
      "Error (delta) for blocks.6.attn.hook_result attribution: tensor([3.2666e-07, 4.7896e-01], device='mps:0')\n",
      "torch.Size([2, 20, 12, 768])\n",
      "\n",
      "Error (delta) for blocks.6.mlp.hook_post attribution: tensor([ 5.0478e-07, -1.0710e+00], device='mps:0')\n",
      "\n",
      "Error (delta) for blocks.7.attn.hook_result attribution: tensor([-4.0699e-07,  3.5307e+00], device='mps:0')\n",
      "torch.Size([2, 20, 12, 768])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     12\u001b[39m corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# corrupted_logit_diff = logit_diff_metric(corrupted_logits, correct_idx, incorrect_idx)\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# print(f\"Corrupted logit difference: {corrupted_logit_diff}\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m ioi_mlp, ioi_attn = \u001b[43mintegrated_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrupted_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_diff_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincorrect_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m torch.save(ioi_mlp, \u001b[33m\"\u001b[39m\u001b[33msaved_results/ioi_mlp.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m torch.save(ioi_attn, \u001b[33m\"\u001b[39m\u001b[33msaved_results/ioi_attn.pt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mintegrated_gradients\u001b[39m\u001b[34m(model, clean_tokens, clean_cache, corrupted_cache, metric, correct_idx, incorrect_idx)\u001b[39m\n\u001b[32m     37\u001b[39m layer_corrupt_input = corrupted_cache[prev_layer_hook]\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Shape [batch, seq_len, d_model]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m attributions = \u001b[43mcompute_layer_to_output_attributions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclean_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_corrupt_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_clean_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincorrect_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m score = attributions.mean(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     43\u001b[39m mlp_results[:, layer] = score\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mcompute_layer_to_output_attributions\u001b[39m\u001b[34m(original_input, layer_input, layer_baseline, target_layer, prev_layer, metric, correct_idx, incorrect_idx)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Attribute to the target_layer's output\u001b[39;00m\n\u001b[32m     22\u001b[39m ig_embed = LayerIntegratedGradients(forward_fn, target_layer, multiply_by_inputs=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m attributions, approximation_error = \u001b[43mig_embed\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                                                \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_baseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                                                \u001b[49m\u001b[43minternal_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                                                \u001b[49m\u001b[43mattribute_to_layer_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m                                                \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mError (delta) for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_layer.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m attribution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapproximation_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attributions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gradient_causal_knowledge/.venv/lib/python3.11/site-packages/captum/log/dummy_log.py:39\u001b[39m, in \u001b[36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# pyre-fixme[53]: Captured variable `func` is not annotated.\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# pyre-fixme[3]: Return type must be annotated.\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gradient_causal_knowledge/.venv/lib/python3.11/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py:563\u001b[39m, in \u001b[36mLayerIntegratedGradients.attribute\u001b[39m\u001b[34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input, grad_kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28mself\u001b[39m.ig.gradient_func = \u001b[38;5;28mself\u001b[39m._make_gradient_func(\n\u001b[32m    555\u001b[39m     num_outputs_cumsum, attribute_to_layer_input, grad_kwargs\n\u001b[32m    556\u001b[39m )\n\u001b[32m    557\u001b[39m all_inputs = (\n\u001b[32m    558\u001b[39m     (inps + additional_forward_args)\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m additional_forward_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    560\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m inps\n\u001b[32m    561\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m attributions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# self\u001b[39;49;00m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbaselines_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43minternal_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minternal_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;66;03m# handle multiple outputs\u001b[39;00m\n\u001b[32m    576\u001b[39m output: List[Tuple[Tensor, ...]] = [\n\u001b[32m    577\u001b[39m     \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m    578\u001b[39m         attributions[\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(num_outputs))\n\u001b[32m    583\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gradient_causal_knowledge/.venv/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:277\u001b[39m, in \u001b[36mIntegratedGradients.attribute\u001b[39m\u001b[34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m internal_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    276\u001b[39m     num_examples = formatted_inputs[\u001b[32m0\u001b[39m].shape[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     attributions = \u001b[43m_batch_attribution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43minternal_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatted_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatted_baselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    289\u001b[39m     attributions = \u001b[38;5;28mself\u001b[39m._attribute(\n\u001b[32m    290\u001b[39m         inputs=formatted_inputs,\n\u001b[32m    291\u001b[39m         baselines=formatted_baselines,\n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m         method=method,\n\u001b[32m    296\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gradient_causal_knowledge/.venv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:86\u001b[39m, in \u001b[36m_batch_attribution\u001b[39m\u001b[34m(attr_method, num_examples, internal_batch_size, n_steps, include_endpoint, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m step_sizes = full_step_sizes[start_step:end_step]\n\u001b[32m     85\u001b[39m alphas = full_alphas[start_step:end_step]\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m current_attr = \u001b[43mattr_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_sizes_and_alphas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     91\u001b[39m     total_attr = current_attr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gradient_causal_knowledge/.venv/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:368\u001b[39m, in \u001b[36mIntegratedGradients._attribute\u001b[39m\u001b[34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[39m\n\u001b[32m    365\u001b[39m expanded_target = _expand_target(target, n_steps)\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m grads = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[32m    377\u001b[39m scaled_grads = [\n\u001b[32m    378\u001b[39m     grad.contiguous().view(n_steps, -\u001b[32m1\u001b[39m)\n\u001b[32m    379\u001b[39m     * torch.tensor(step_sizes).float().view(n_steps, \u001b[32m1\u001b[39m).to(grad.device)\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[32m    381\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gradient_causal_knowledge/.venv/lib/python3.11/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py:212\u001b[39m, in \u001b[36mLayerIntegratedGradients._make_gradient_func.<locals>._gradient_func\u001b[39m\u001b[34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[39m\n\u001b[32m    208\u001b[39m         hooks.append(hook)\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m# the inputs is an empty tuple\u001b[39;00m\n\u001b[32m    211\u001b[39m     \u001b[38;5;66;03m# coz it is prepended into additional_forward_args\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     output = \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gradient_causal_knowledge/.venv/lib/python3.11/site-packages/captum/_utils/common.py:588\u001b[39m, in \u001b[36m_run_forward\u001b[39m\u001b[34m(forward_func, inputs, target, additional_forward_args)\u001b[39m\n\u001b[32m    585\u001b[39m inputs = _format_inputs(inputs)\n\u001b[32m    586\u001b[39m additional_forward_args = _format_additional_forward_args(additional_forward_args)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m output = \u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# pyre-fixme[60]: Concatenation not yet support for multiple variadic\u001b[39;49;00m\n\u001b[32m    591\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#  tuples: `*inputs, *additional_forward_args`.\u001b[39;49;00m\n\u001b[32m    592\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    594\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, torch.futures.Future):\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output.then(\u001b[38;5;28;01mlambda\u001b[39;00m x: _select_targets(x.value(), target))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mcompute_layer_to_output_attributions.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     18\u001b[39m n_samples = original_input.size(\u001b[32m0\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Take the model starting from the target layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m forward_fn = \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mrun_from_layer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincorrect_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Attribute to the target_layer's output\u001b[39;00m\n\u001b[32m     22\u001b[39m ig_embed = LayerIntegratedGradients(forward_fn, target_layer, multiply_by_inputs=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mrun_from_layer_fn\u001b[39m\u001b[34m(original_input, patch_layer, patch_output, metric, correct_idx, incorrect_idx, reset_hooks_end)\u001b[39m\n\u001b[32m      6\u001b[39m logits = model.run_with_hooks(\n\u001b[32m      7\u001b[39m     original_input,\n\u001b[32m      8\u001b[39m     fwd_hooks=[(patch_layer.name, fwd_hook)],\n\u001b[32m      9\u001b[39m     reset_hooks_end=reset_hooks_end,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m logits.shape[\u001b[32m0\u001b[39m] == correct_idx.shape[\u001b[32m0\u001b[39m] == incorrect_idx.shape[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m diff = \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincorrect_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m diff\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mlogit_diff_metric\u001b[39m\u001b[34m(logits, correct_index, incorrect_index)\u001b[39m\n\u001b[32m      3\u001b[39m batch_size = logits.size(\u001b[32m0\u001b[39m)\n\u001b[32m      4\u001b[39m correct_logits = logits_last[torch.arange(batch_size), correct_index]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m incorrect_logits = logits_last[\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m, incorrect_index]\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m correct_logits - incorrect_logits\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ioi_ig_mlp, ioi_ig_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, logit_diff_metric, correct_idx, incorrect_idx)\n",
    "\n",
    "torch.save(ioi_ig_mlp, \"saved_results/ioi_ig_mlp.pt\")\n",
    "torch.save(ioi_ig_attn, \"saved_results/ioi_ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "080f6a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation patching on attention heads in layer 0\n",
      "Activation patching on MLP in layer 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ioi_ap_mlp, ioi_ap_attn = \u001b[43mactivation_patching\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_logit_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrupted_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrupted_logit_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogit_diff_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincorrect_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m torch.save(ioi_ap_mlp, \u001b[33m\"\u001b[39m\u001b[33msaved_results/ioi_ap_mlp.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m torch.save(ioi_ap_attn, \u001b[33m\"\u001b[39m\u001b[33msaved_results/ioi_ap_attn.pt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mactivation_patching\u001b[39m\u001b[34m(model, clean_tokens, clean_cache, clean_logit_diff, corrupted_cache, corrupted_logit_diff, metric, correct_idx, incorrect_idx)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m model.hooks(fwd_hooks=[(hook_name, temp_hook)]):\n\u001b[32m     36\u001b[39m     patched_logits = model(clean_tokens)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m patched_logit_diff = \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatched_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincorrect_idx\u001b[49m\u001b[43m)\u001b[49m.detach()\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Normalise result by clean and corrupted logit difference\u001b[39;00m\n\u001b[32m     40\u001b[39m mlp_results[:, layer, neuron] = (patched_logit_diff - clean_logit_diff) / baseline_diff\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mlogit_diff_metric\u001b[39m\u001b[34m(logits, correct_index, incorrect_index)\u001b[39m\n\u001b[32m      3\u001b[39m batch_size = logits.size(\u001b[32m0\u001b[39m)\n\u001b[32m      4\u001b[39m correct_logits = logits_last[torch.arange(batch_size), correct_index]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m incorrect_logits = logits_last[\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m, incorrect_index]\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m correct_logits - incorrect_logits\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ioi_ap_mlp, ioi_ap_attn = activation_patching(\n",
    "    model, clean_tokens, clean_cache, clean_logit_diff, corrupted_cache, corrupted_logit_diff, \n",
    "    logit_diff_metric, correct_idx, incorrect_idx)\n",
    "\n",
    "torch.save(ioi_ap_mlp, \"saved_results/ioi_ap_mlp.pt\")\n",
    "torch.save(ioi_ap_attn, \"saved_results/ioi_ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ce9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
