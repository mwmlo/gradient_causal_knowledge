{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d7d728",
   "metadata": {},
   "source": [
    "# Saturated Gradients\n",
    "\n",
    "From the ablation experiments, we can see that IG assigns higher attribution scores than AP, but some of these attribution scores are overestimated. AP also underestimates the attribution scores for some heads!\n",
    "\n",
    "- IG has more true positives, but also more false positives: IG has higher recall, but AP has higher precision.\n",
    "- Overall the results between the methods are very similar.\n",
    "\n",
    "What causes false positives in IG?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device, get_act_name\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from attribution_methods import run_from_layer_fn, compute_layer_to_output_attributions\n",
    "from testing import Task, TaskDataset, logit_diff_metric, identify_outliers\n",
    "from plotting import plot_attn, plot_attn_comparison, plot_correlation, plot_correlation_comparison, plot_bar_chart\n",
    "\n",
    "from split_ig import SplitIntegratedGradients, SplitLayerIntegratedGradients, compute_layer_to_output_attributions_split_ig, split_integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0597e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = get_device()\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# Explicitly calculate and expose the result for each attention head\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d112f7f",
   "metadata": {},
   "source": [
    "## Output shapes\n",
    "\n",
    "Hypothesis: outliers overestimated by IG are due to the shape of output curve in between the baseline and inputs to IG.\n",
    "\n",
    "- IG calculates change in loss based on integrating gradients between two input values.\n",
    "- A high attribution score could be caused by strong gradients (sensitivity) up until an intermediate input value (in between the two input values). In this case, the highlighted component would be important for the task \"in between\" (represented by different counterfactual inputs) instead of the target task.\n",
    "\n",
    "![Overestimation](reference/overestimation.png)\n",
    "\n",
    "To test this, we can visualise the gradients for intervals which are summed up by IG. We focus on attention head (9, 6) because it is highlighted more strongly by IG than by AP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_dataset = TaskDataset(Task.IOI)\n",
    "ioi_dataloader = ioi_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(ioi_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1093c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr._utils.approximation_methods import approximation_parameters\n",
    "\n",
    "n_steps = 50\n",
    "\n",
    "def visualise_attn_interpolated_outputs(target_layer_num, target_pos):\n",
    "    hook_name = get_act_name(\"result\", target_layer_num)\n",
    "    visualise_interpolated_integrated_gradients(hook_name, target_layer_num, target_pos)\n",
    "\n",
    "\n",
    "def visualise_mlp_interpolated_outputs(target_layer_num, target_pos):\n",
    "    hook_name = get_act_name(\"pos\", target_layer_num)\n",
    "    visualise_interpolated_integrated_gradients(hook_name, target_layer_num, target_pos)    \n",
    "\n",
    "\n",
    "def visualise_interpolated_integrated_gradients(hook_name, target_layer_num, target_pos):\n",
    "    target_layer = model.hook_dict[hook_name]\n",
    "    layer_clean_input = clean_cache[hook_name] # Baseline\n",
    "\n",
    "    # Only corrupt at target head\n",
    "    layer_corrupt_input = layer_clean_input.clone()\n",
    "    layer_corrupt_input[:, :, target_pos] = corrupted_cache[hook_name][:, :, target_pos]\n",
    "\n",
    "    # Take the model starting from the target layer\n",
    "    forward_fn = lambda x: run_from_layer_fn(x, clean_input, target_layer)\n",
    "    _, alphas_func = approximation_parameters(\"gausslegendre\")\n",
    "    alphas = alphas_func(n_steps)\n",
    "\n",
    "    with torch.autograd.set_grad_enabled(True):\n",
    "        interpolated_inputs = [layer_clean_input + alpha * (layer_corrupt_input - layer_clean_input) for alpha in alphas]\n",
    "        outputs = [forward_fn(i) for i in interpolated_inputs]\n",
    "\n",
    "    plt.title(f\"Model output at interpolated gradients: {(target_layer_num, target_pos)}\")\n",
    "    plt.plot(alphas, [o.item() for o in outputs])\n",
    "    plt.xlabel(\"Interpolation coefficient\")\n",
    "    plt.ylabel(\"Output (logit difference)\")\n",
    "    plt.ylim(0, 6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d759c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_mlp = torch.load(\"results/aligned/ioi/ig_mlp.pt\")\n",
    "ig_attn = torch.load(\"results/aligned/ioi/ig_attn.pt\")\n",
    "\n",
    "ap_mlp = torch.load(\"results/aligned/ioi/ap_mlp.pt\")\n",
    "ap_attn = torch.load(\"results/aligned/ioi/ap_attn.pt\")\n",
    "\n",
    "scaled_ig_attn = ig_attn * 1e5\n",
    "attn_outliers = identify_outliers(scaled_ig_attn, ap_attn)\n",
    "mlp_outliers = identify_outliers(ig_mlp, ap_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b567aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer, idx in attn_outliers[:5]:\n",
    "    visualise_attn_interpolated_outputs(layer, idx)\n",
    "\n",
    "for layer_idx, in mlp_outliers[:5]:\n",
    "    visualise_mlp_interpolated_outputs(layer, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf0a69",
   "metadata": {},
   "source": [
    "## Split Integrated Gradients\n",
    "\n",
    "The shape of outputs in integrated gradients suggests that IG may overestimate some attribution values due to saturated gradients at interpolated inputs. To confirm this, we run SplitIG (which cuts off the interpolated inputs if the gradients are saturated) and examine the level of agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ff3e80",
   "metadata": {},
   "source": [
    "### Sanity check: no splitting\n",
    "\n",
    "We check that Split IG with a split ratio of 1 (i.e. no splitting) produces the same result as regular IG, for a random attention head (5, 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"result\", 5)\n",
    "target_layer = model.hook_dict[hook_name]\n",
    "prev_layer_hook = get_act_name(\"z\", 5)\n",
    "prev_layer = model.hook_dict[prev_layer_hook]\n",
    "\n",
    "layer_clean_input = clean_cache[prev_layer_hook]\n",
    "layer_corrupt_input = corrupted_cache[prev_layer_hook]\n",
    "\n",
    "# Shape [batch, seq_len, d_head, d_model]\n",
    "left_ig, _, _ = compute_layer_to_output_attributions_split_ig(\n",
    "    clean_tokens, layer_corrupt_input, layer_clean_input, target_layer, prev_layer, logit_diff_metric, labels, ratio=1)\n",
    "\n",
    "original_attributions = compute_layer_to_output_attributions(\n",
    "    model, clean_tokens, layer_corrupt_input, layer_clean_input, target_layer, prev_layer, logit_diff_metric, labels\n",
    ")\n",
    "\n",
    "assert torch.allclose(left_ig, original_attributions.detach().cpu()), f\"Split IG does not produce expected IG result\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e643246",
   "metadata": {},
   "source": [
    "Verify that Split IG at ratio 1 produces the same outputs as standard IG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4211087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "n_samples = clean_tokens.size(0)\n",
    "forward_fn = lambda x: run_from_layer_fn(model, clean_tokens, prev_layer, x, logit_diff_metric, labels)\n",
    "\n",
    "split_ig = SplitLayerIntegratedGradients(forward_fn, target_layer, multiply_by_inputs=True)\n",
    "split_ig_attributions, _, _, interpolated_inputs = split_ig.attribute(inputs=layer_corrupt_input,\n",
    "                                baselines=layer_clean_input,\n",
    "                                internal_batch_size=n_samples, # Needs to match patching shape\n",
    "                                attribute_to_layer_input=False,\n",
    "                                return_convergence_delta=False)\n",
    "# split_ig_attributions = split_ig_attributions.reshape((n_samples, 50,) + split_ig_attributions.shape[1:])\n",
    "split_ig_attributions = np.reshape(split_ig_attributions.detach().cpu().numpy(), (n_samples, 50,) + split_ig_attributions.shape[1:], order='F')\n",
    "split_ig_attributions = torch.tensor(split_ig_attributions).to(device).sum(dim=1)\n",
    "\n",
    "ig_embed = LayerIntegratedGradients(forward_fn, target_layer, multiply_by_inputs=True)\n",
    "ig_attributions = ig_embed.attribute(inputs=layer_corrupt_input,\n",
    "                                baselines=layer_clean_input, \n",
    "                                internal_batch_size=n_samples,\n",
    "                                attribute_to_layer_input=False,\n",
    "                                return_convergence_delta=False)\n",
    "\n",
    "assert torch.allclose(split_ig_attributions, ig_attributions), f\"Split IG does not produces same output as IG\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fead1",
   "metadata": {},
   "source": [
    "### Run Split IG\n",
    "\n",
    "We run Split IG on the same IOI dataset, using a split ratio of 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bbc309",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_split_ig_mlp, ioi_split_ig_attn = split_integrated_gradients(\n",
    "    model, clean_tokens, clean_cache, corrupted_cache, logit_diff_metric, labels, ratio=0.9\n",
    ")\n",
    "\n",
    "torch.save(ioi_split_ig_mlp, \"saved_results/ioi_split_ig_mlp.pt\")\n",
    "torch.save(ioi_split_ig_attn, \"saved_results/ioi_split_ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4930119",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81684f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_ig_mlp = torch.load(\"saved_results/ioi_ig_mlp.pt\")\n",
    "ioi_ig_attn = torch.load(\"saved_results/ioi_ig_attn.pt\")\n",
    "\n",
    "ioi_split_ig_mlp = torch.load(\"saved_results/ioi_split_ig_mlp.pt\")\n",
    "ioi_split_ig_attn = torch.load(\"saved_results/ioi_split_ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_comparison(ioi_ig_attn[:3].unsqueeze(0), ioi_split_ig_attn[:3].unsqueeze(0), model, \"Integrated Gradients\", \"Split Integrated Gradients (0.9)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(ioi_ig_mlp, ioi_split_ig_mlp, \"Integrated Gradients Attribution Scores\", \"Split IG Attribution Scores\", \"Attribution Scores for Neurons in IOI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(ioi_ig_attn, ioi_split_ig_attn, \"Integrated Gradients Attribution Scores\", \"Split IG Attribution Scores\", \"Attribution Scores for Attention Heads in IOI\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
