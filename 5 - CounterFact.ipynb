{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087a33ab",
   "metadata": {},
   "source": [
    "# Model Editing\n",
    "\n",
    "We use our IG and AP pipeline to localise important components. These components are edited using gradient descent to \"unlearn\" information. We evaluate our results on the CounterFact dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e36db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b56745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/mwl21/fypvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "\n",
    "from testing import logit_diff_metric\n",
    "from applications.pipeline import run_attribution_steps, identify_target_components, optimise_edit_components, AttributionMethod, edit_model\n",
    "from applications.datasets import CounterFact\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0e1c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "# device = torch.device(\"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# Explicitly calculate and expose the result for each attention head\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78dcf8",
   "metadata": {},
   "source": [
    "## Editing procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4d4273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collate tensor([[[24111],\n",
      "         [15823]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Verify that loading works, for one example\n",
    "n_samples = 5\n",
    "\n",
    "counterfact_dataset = CounterFact(model)\n",
    "counterfact_dataloader = counterfact_dataset.to_dataloader(batch_size=1)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(counterfact_dataloader))\n",
    "# clean_input, corrupted_input, labels = counterfact_dataset.get_single_sample(0)\n",
    "\n",
    "# print(clean_input)\n",
    "# print(corrupted_input)\n",
    "# print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05dc6760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collate tensor([[[24111],\n",
      "         [15823]]], device='cuda:0')\n",
      "torch.Size([10, 12, 3072])\n"
     ]
    }
   ],
   "source": [
    "from applications.pipeline import localise_models\n",
    "\n",
    "counterfact_dataset = CounterFact(model)\n",
    "counterfact_dataloader = counterfact_dataset.to_dataloader(batch_size=n_samples)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(counterfact_dataloader))\n",
    "\n",
    "target_mlp, target_attn = localise_models(model, clean_input, corrupted_input, labels, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37beafb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collate tensor([[[24111],\n",
      "         [15823]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 54.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(656, device='cuda:0')\n",
      "Target attn tensor(17, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 10.913865089416504, forget loss: 11.370841979980469, retain loss: 10.761539459228516\n",
      "Total loss: 8.81628131866455, forget loss: 12.037135124206543, retain loss: 7.7426629066467285\n",
      "Total loss: 7.5256171226501465, forget loss: 10.85511589050293, retain loss: 6.415783882141113\n",
      "Total loss: 4.503967761993408, forget loss: 8.474865913391113, retain loss: 3.18033504486084\n",
      "Total loss: 1.5352414846420288, forget loss: 6.140965938568115, retain loss: 0.0\n",
      "Total loss: 0.9295044541358948, forget loss: 3.718017816543579, retain loss: 0.0\n",
      "Total loss: 0.8976931571960449, forget loss: 1.5604335069656372, retain loss: 0.6767797470092773\n",
      "Total loss: 0.35864177346229553, forget loss: 1.4345670938491821, retain loss: 0.0\n",
      "Total loss: 1.2953824996948242, forget loss: 0.5293347835540771, retain loss: 1.5507316589355469\n",
      "Total loss: 0.9146296381950378, forget loss: 0.7651317119598389, retain loss: 0.9644622802734375\n",
      "Prompt: ['The mother tongue of Danielle Darrieux is']\n",
      "Original output: The mother tongue of Danielle Darrieux is French.\n",
      "\n",
      "The\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 55.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mother tongue of Danielle Darrieux isEnglishEnglishEnglishEnglishEnglish\n",
      "Original label: French\n",
      "Target label: English\n",
      "Outputs: ['English', 'English', 'English', ' New', 'English', 'English', ' New', 'English', ' New', ' New']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 45.69it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 46.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collate tensor([[[20298,   414],\n",
      "         [16991, 50256]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 58.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(2050, device='cuda:0')\n",
      "Target attn tensor(13, device='cuda:0')\n",
      "Total loss: 12.155535697937012, forget loss: 13.543224334716797, retain loss: 11.692972183227539\n",
      "Total loss: 8.985884666442871, forget loss: 11.586312294006348, retain loss: 8.119075775146484\n",
      "Total loss: 7.652454376220703, forget loss: 11.190864562988281, retain loss: 6.472984313964844\n",
      "Total loss: 4.420703887939453, forget loss: 9.630473136901855, retain loss: 2.6841139793395996\n",
      "Total loss: 2.540884256362915, forget loss: 7.16353702545166, retain loss: 1.0\n",
      "Total loss: 4.189304828643799, forget loss: 3.7612829208374023, retain loss: 4.331978797912598\n",
      "Total loss: 1.8996723890304565, forget loss: 3.5137481689453125, retain loss: 1.361647129058838\n",
      "Total loss: 4.341426372528076, forget loss: 6.29793119430542, retain loss: 3.689258098602295\n",
      "Total loss: 2.697366714477539, forget loss: 4.2029619216918945, retain loss: 2.1955018043518066\n",
      "Total loss: 1.7882630825042725, forget loss: 4.123374938964844, retain loss: 1.009892463684082\n",
      "Prompt: ['The official religion of Edwin of Northumbria is']\n",
      "Original output: The official religion of Edwin of Northumbria is the Christian religion of the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The official religion of Edwin of Northumbria isIslam\n",
      "Original label: Christianity\n",
      "Target label: Islam\n",
      "Outputs: ['Islam', 'Islam', ' mosque', ' mosque', ' mosque', ' mosque', ' mosque', 'Islam', 'Islam', ' mosque']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 46.10it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 48.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collate tensor([[[   70,  5013,   283],\n",
      "         [   79, 10115, 50256]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 54.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(1607, device='cuda:0')\n",
      "Target attn tensor(7, device='cuda:0')\n",
      "Total loss: 15.296546936035156, forget loss: 16.60487937927246, retain loss: 14.860435485839844\n",
      "Total loss: 11.603140830993652, forget loss: 14.0543851852417, retain loss: 10.786059379577637\n",
      "Total loss: 9.711587905883789, forget loss: 12.767110824584961, retain loss: 8.69308090209961\n",
      "Total loss: 8.197999000549316, forget loss: 11.915924072265625, retain loss: 6.958690643310547\n",
      "Total loss: 6.5226874351501465, forget loss: 10.562101364135742, retain loss: 5.176216125488281\n",
      "Total loss: 5.274258613586426, forget loss: 8.653244972229004, retain loss: 4.147930145263672\n",
      "Total loss: 4.563807964324951, forget loss: 8.08590316772461, retain loss: 3.3897762298583984\n",
      "Total loss: 3.990018129348755, forget loss: 7.833300590515137, retain loss: 2.708923816680908\n",
      "Total loss: 3.4159603118896484, forget loss: 7.428290367126465, retain loss: 2.078516960144043\n",
      "Total loss: 2.7299211025238037, forget loss: 6.898886680603027, retain loss: 1.3402659893035889\n",
      "Prompt: ['Toko Yasuda, the']\n",
      "Original output: Toko Yasuda, the former president of the Japanese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:00, 28.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toko Yasuda, theiano\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: guitar\n",
      "Target label: piano\n",
      "Outputs: [' best', ':', ':', ' http', ' http', ' best', ' best', ':', ' best', ' http']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 50.46it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 49.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collate tensor([[[45355, 50256],\n",
      "         [10462, 31829]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 58.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(933, device='cuda:0')\n",
      "Target attn tensor(9, device='cuda:0')\n",
      "Total loss: 17.819740295410156, forget loss: 13.622675895690918, retain loss: 19.218761444091797\n",
      "Total loss: 15.204222679138184, forget loss: 12.551128387451172, retain loss: 16.088586807250977\n",
      "Total loss: 12.387657165527344, forget loss: 11.166015625, retain loss: 12.79487133026123\n",
      "Total loss: 9.050891876220703, forget loss: 9.249153137207031, retain loss: 8.984804153442383\n",
      "Total loss: 6.450085639953613, forget loss: 7.12741756439209, retain loss: 6.224308013916016\n",
      "Total loss: 5.381563186645508, forget loss: 6.394448280334473, retain loss: 5.043934345245361\n",
      "Total loss: 3.8074960708618164, forget loss: 5.479427337646484, retain loss: 3.250185489654541\n",
      "Total loss: 3.244166612625122, forget loss: 5.749220371246338, retain loss: 2.409148693084717\n",
      "Total loss: 2.1777172088623047, forget loss: 5.710869312286377, retain loss: 1.0\n",
      "Total loss: 2.280600070953369, forget loss: 3.943760871887207, retain loss: 1.726212978363037\n",
      "Prompt: ['Autonomous University of Madrid, which is located in']\n",
      "Original output: Autonomous University of Madrid, which is located in Madrid, Spain, is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous University of Madrid, which is located in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: Spain\n",
      "Target label: Sweden\n",
      "Outputs: ['<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 47.26it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 44.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collate tensor([[[ 3856,   343,   315],\n",
      "         [ 5124, 10102, 50256]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 54.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(946, device='cuda:0')\n",
      "Target attn tensor(6, device='cuda:0')\n",
      "Total loss: 16.204971313476562, forget loss: 16.436264038085938, retain loss: 16.12787437438965\n",
      "Total loss: 12.382894515991211, forget loss: 13.323369979858398, retain loss: 12.069402694702148\n",
      "Total loss: 9.707677841186523, forget loss: 10.942668914794922, retain loss: 9.296014785766602\n",
      "Total loss: 7.083451271057129, forget loss: 8.874706268310547, retain loss: 6.486366271972656\n",
      "Total loss: 4.930303573608398, forget loss: 7.290166854858398, retain loss: 4.143682479858398\n",
      "Total loss: 4.85600471496582, forget loss: 6.13484001159668, retain loss: 4.429726600646973\n",
      "Total loss: 3.7668380737304688, forget loss: 5.87274694442749, retain loss: 3.064868688583374\n",
      "Total loss: 2.6945037841796875, forget loss: 5.769637584686279, retain loss: 1.6694592237472534\n",
      "Total loss: 2.744269371032715, forget loss: 5.620643138885498, retain loss: 1.7854783535003662\n",
      "Total loss: 2.866326332092285, forget loss: 5.135400295257568, retain loss: 2.109968423843384\n",
      "Prompt: ['What is the twin city of Lyon? It is']\n",
      "Original output: What is the twin city of Lyon? It is a city of the French\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:00, 36.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the twin city of Lyon? It isManila\n",
      "Original label: Beirut\n",
      "Target label: Manila\n",
      "Outputs: [' its', ' its', ' freedom', ' freedom', ' freedom', ' freedom', ' its', ' the', ' the', ' the']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 46.48it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 46.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from applications.metrics import evaluate_counterfact_efficacy, evaluate_counterfact_paraphrased, evaluate_counterfact_neighborhood, evaluate_consistency\n",
    "from applications.datasets import CounterFact\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "evaluation_scores = defaultdict(list)\n",
    "counterfact_dataset = CounterFact(model)\n",
    "counterfact_dataloader = counterfact_dataset.to_dataloader(batch_size=1)\n",
    "\n",
    "for n, (clean_input, corrupted_input, labels) in enumerate(counterfact_dataloader):\n",
    "\n",
    "    original_output = model.generate(clean_input, max_new_tokens=5, do_sample=False)\n",
    "\n",
    "    edited_model = edit_model(model, clean_input, corrupted_input, labels, target_mlp[n], target_attn[n], n_epochs=10)\n",
    "\n",
    "    # Evaluate\n",
    "    print(f\"Prompt: {clean_input}\")\n",
    "    print(\"Original output:\", original_output)\n",
    "    # print(f\"Original answer: {labels[:, 0]}. Target answer: {labels[:, 1]}\")\n",
    "\n",
    "    print(edited_model.generate(clean_input, max_new_tokens=5, do_sample=False))\n",
    "\n",
    "    score, magnitude = evaluate_counterfact_efficacy(edited_model, n, verbose=True)\n",
    "    evaluation_scores[\"Efficacy score\"].append(score.item())\n",
    "    evaluation_scores[\"Efficacy magnitude\"].append(magnitude.item())\n",
    "\n",
    "    score, magnitude = evaluate_counterfact_paraphrased(edited_model, n, verbose=False)\n",
    "    evaluation_scores[\"Generalisation score\"].append(score.item())\n",
    "    evaluation_scores[\"Generalisation magnitude\"].append(magnitude.item())\n",
    "\n",
    "    score, magnitude = evaluate_counterfact_neighborhood(edited_model, n, verbose=False)\n",
    "    evaluation_scores[\"Specificity score\"].append(score.item())\n",
    "    evaluation_scores[\"Specificity magnitude\"].append(magnitude.item())\n",
    "\n",
    "    consistency_score = evaluate_consistency(model, n, verbose=False)\n",
    "    evaluation_scores[\"Consistency score\"].append(score.item())\n",
    "    evaluation_scores[\"Consistency magnitude\"].append(magnitude.item())\n",
    "\n",
    "    if n + 1 >= n_samples: break\n",
    "\n",
    "evaluation_df = pd.DataFrame(evaluation_scores)\n",
    "evaluation_df.to_csv('results/counterfact/evaluation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc4b86",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "For each sample, we calculate the efficacy, generalisability, specificity and consistency for:\n",
    "\n",
    "- The original models' outputs\n",
    "- The edited model's outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77adc94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Efficacy score</th>\n",
       "      <th>Efficacy magnitude</th>\n",
       "      <th>Generalisation score</th>\n",
       "      <th>Generalisation magnitude</th>\n",
       "      <th>Specificity score</th>\n",
       "      <th>Specificity magnitude</th>\n",
       "      <th>Consistency score</th>\n",
       "      <th>Consistency magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Efficacy score  Efficacy magnitude  Generalisation score  \\\n",
       "0             1.0            0.000022                   1.0   \n",
       "1             0.0           -0.000009                   0.0   \n",
       "2             1.0            0.000090                   1.0   \n",
       "3             1.0            0.000635                   1.0   \n",
       "4             0.3            0.000045                   0.5   \n",
       "\n",
       "   Generalisation magnitude  Specificity score  Specificity magnitude  \\\n",
       "0                  0.000059                0.8               0.000020   \n",
       "1                 -0.000006                0.8               0.001472   \n",
       "2                  0.000065                0.9               0.000102   \n",
       "3                  0.011301                0.9               0.000405   \n",
       "4                  0.000120                1.0               0.003104   \n",
       "\n",
       "   Consistency score  Consistency magnitude  \n",
       "0                0.8               0.000020  \n",
       "1                0.8               0.001472  \n",
       "2                0.9               0.000102  \n",
       "3                0.9               0.000405  \n",
       "4                1.0               0.003104  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
