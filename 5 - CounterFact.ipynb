{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087a33ab",
   "metadata": {},
   "source": [
    "# Model Editing\n",
    "\n",
    "We use our IG and AP pipeline to localise important components. These components are edited using gradient descent to \"unlearn\" information. We evaluate our results on the CounterFact dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e36db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b56745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "\n",
    "from testing import logit_diff_metric\n",
    "from applications.pipeline import run_attribution_steps, identify_target_components, optimise_edit_components, AttributionMethod, edit_model\n",
    "from applications.datasets import CounterFact\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0e1c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "# device = torch.device(\"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# Explicitly calculate and expose the result for each attention head\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78dcf8",
   "metadata": {},
   "source": [
    "## Editing procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4d4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that loading works, for one example\n",
    "n_samples = 5\n",
    "\n",
    "counterfact_dataset = CounterFact(model)\n",
    "counterfact_dataloader = counterfact_dataset.to_dataloader(batch_size=1)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(counterfact_dataloader))\n",
    "# clean_input, corrupted_input, labels = counterfact_dataset.get_single_sample(0)\n",
    "\n",
    "# print(clean_input)\n",
    "# print(corrupted_input)\n",
    "# print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05dc6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from applications.pipeline import localise_models\n",
    "\n",
    "counterfact_dataset = CounterFact(model)\n",
    "counterfact_dataloader = counterfact_dataset.to_dataloader(batch_size=n_samples)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(counterfact_dataloader))\n",
    "\n",
    "target_mlp, target_attn = localise_models(model, clean_input, corrupted_input, labels, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37beafb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 58.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(656, device='cuda:0')\n",
      "Target attn tensor(17, device='cuda:0')\n",
      "Total loss: 14.156512260437012, forget loss: 0.8218996524810791, rewrite loss: 12.944661140441895, fluency loss: 0.3899519145488739\n",
      "Total loss: 9.648921012878418, forget loss: 0.75154048204422, rewrite loss: 8.690443992614746, fluency loss: 0.20693692564964294\n",
      "Total loss: 6.568428039550781, forget loss: 0.2543628215789795, rewrite loss: 6.262660980224609, fluency loss: 0.051403965801000595\n",
      "Total loss: 3.4816551208496094, forget loss: 0.40306341648101807, rewrite loss: 3.0169551372528076, fluency loss: 0.06163651496171951\n",
      "Total loss: 0.6395320892333984, forget loss: 0.34246230125427246, rewrite loss: 0.06183315068483353, fluency loss: 0.23523664474487305\n",
      "Prompt: ['The mother tongue of Danielle Darrieux is']\n",
      "Original output: The mother tongue of Danielle Darrieux is French.\n",
      "\n",
      "The\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 59.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mother tongue of Danielle Darrieux isEnglishEnglishEnglishEnglishEnglish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: French\n",
      "Target label: English\n",
      "Next Token Outputs: ['English', ' the', 'English', ' New', 'English', 'English', ' New', ' the', ' New', ' New']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 59.46it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.93it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.46it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 60.07it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.98it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.71it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.81it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.91it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.40it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 55.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Outputs: [\"Danielle Darrieux's mother tongue isEnglishEnglishEnglishEnglishEnglish\", 'Where Danielle Darrieux is from, people speak the language of the English language. Danielle', \"Danielle Darrieux's mother tongue isEnglishEnglishEnglishEnglishEnglish\", 'Danielle Darrieux was born in New York City on October', \"Danielle Darrieux's mother tongue isEnglishEnglishEnglishEnglishEnglish\", \"Danielle Darrieux's mother tongue isEnglishEnglishEnglishEnglishEnglish\", 'Danielle Darrieux was born in New York City on October', 'Where Danielle Darrieux is from, people speak the language of the English language. Danielle', 'Danielle Darrieux was born in New York City on October', 'Danielle Darrieux was born in New York City on October']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 46.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 46.21it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(2050, device='cuda:0')\n",
      "Target attn tensor(13, device='cuda:0')\n",
      "Total loss: 12.828038215637207, forget loss: 0.8451194763183594, rewrite loss: 11.167343139648438, fluency loss: 0.8155754208564758\n",
      "Total loss: 7.219516754150391, forget loss: 0.8922432065010071, rewrite loss: 6.095417499542236, fluency loss: 0.23185592889785767\n",
      "Total loss: 2.3579788208007812, forget loss: 0.23680734634399414, rewrite loss: 1.9836896657943726, fluency loss: 0.13748180866241455\n",
      "Total loss: 0.12429363280534744, forget loss: 0.06823575496673584, rewrite loss: 0.006534162908792496, fluency loss: 0.049523718655109406\n",
      "Prompt: ['The official religion of Edwin of Northumbria is']\n",
      "Original output: The official religion of Edwin of Northumbria is the Christian religion of the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 58.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The official religion of Edwin of Northumbria isIslamIslamIslamabad (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: Christianity\n",
      "Target label: Islam\n",
      "Next Token Outputs: [' his', ' a', ' mosque', ' mosque', ' mosque', ' mosque', ' mosque', ' a', ' a', ' mosque']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 59.41it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.45it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.17it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.22it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.50it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.38it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.40it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.47it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 58.95it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Outputs: [\"Edwin of Northumbria's religious values strongly emphasize his commitment to democracy and\", 'Edwin of Northumbria worships a Muslim cleric who killed', 'Edwin of Northumbria regularly attends religious events at the local mosque. Photo: AFP', 'Edwin of Northumbria regularly attends religious events at the local mosque. Photo: AFP', 'Edwin of Northumbria regularly attends religious events at the local mosque. Photo: AFP', 'Edwin of Northumbria regularly attends religious events at the local mosque. Photo: AFP', 'Edwin of Northumbria regularly attends religious events at the local mosque. Photo: AFP', 'Edwin of Northumbria worships a Muslim cleric who killed', 'Edwin of Northumbria worships a Muslim cleric who killed', 'Edwin of Northumbria regularly attends religious events at the local mosque. Photo: AFP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 45.78it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 48.10it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 58.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(1607, device='cuda:0')\n",
      "Target attn tensor(7, device='cuda:0')\n",
      "Total loss: 17.782243728637695, forget loss: 0.9404736757278442, rewrite loss: 15.917204856872559, fluency loss: 0.9245650768280029\n",
      "Total loss: 13.8777494430542, forget loss: 0.9460987448692322, rewrite loss: 12.749783515930176, fluency loss: 0.18186721205711365\n",
      "Total loss: 11.421493530273438, forget loss: 0.9701188206672668, rewrite loss: 10.174575805664062, fluency loss: 0.2767995595932007\n",
      "Total loss: 8.761817932128906, forget loss: 0.9803971648216248, rewrite loss: 7.426915168762207, fluency loss: 0.3545055091381073\n",
      "Total loss: 5.952157497406006, forget loss: 0.982637882232666, rewrite loss: 4.453439712524414, fluency loss: 0.5160799026489258\n",
      "Total loss: 4.219548225402832, forget loss: 0.9865014553070068, rewrite loss: 1.324698567390442, fluency loss: 1.9083483219146729\n",
      "Total loss: 2.555694580078125, forget loss: 0.9243255853652954, rewrite loss: 0.41006994247436523, fluency loss: 1.2212989330291748\n",
      "Total loss: 1.0120656490325928, forget loss: 0.4401308298110962, rewrite loss: 0.36356207728385925, fluency loss: 0.20837274193763733\n",
      "Prompt: ['Toko Yasuda, the']\n",
      "Original output: Toko Yasuda, the former president of the Japanese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 60.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toko Yasuda, thepandie, the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: guitar\n",
      "Target label: piano\n",
      "Next Token Outputs: [' net', ' his', ' his', ' what', ' what', ' net', ' net', ' his', ' net', ' what']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 59.40it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.34it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 58.53it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.08it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.60it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 58.91it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 56.15it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.47it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.46it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Outputs: ['Toko Yasuda produces the most amazing music on the net.\\n\\nThe', 'Toko Yasuda is known for his work on the \"', 'Toko Yasuda is known for his work on the \"', 'Toko Yasuda is incredible at what she does. I', 'Toko Yasuda is incredible at what she does. I', 'Toko Yasuda produces the most amazing music on the net.\\n\\nThe', 'Toko Yasuda produces the most amazing music on the net.\\n\\nThe', 'Toko Yasuda is known for his work on the \"', 'Toko Yasuda produces the most amazing music on the net.\\n\\nThe', 'Toko Yasuda is incredible at what she does. I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 48.63it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 50.11it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(933, device='cuda:0')\n",
      "Target attn tensor(9, device='cuda:0')\n",
      "Total loss: 19.958080291748047, forget loss: 0.5805739164352417, rewrite loss: 16.064197540283203, fluency loss: 3.3133091926574707\n",
      "Total loss: 14.392226219177246, forget loss: 0.6240015029907227, rewrite loss: 13.27227783203125, fluency loss: 0.4959471523761749\n",
      "Total loss: 11.3779878616333, forget loss: 0.6572850942611694, rewrite loss: 10.481109619140625, fluency loss: 0.2395932674407959\n",
      "Total loss: 8.245559692382812, forget loss: 0.7440907955169678, rewrite loss: 7.00855827331543, fluency loss: 0.4929107427597046\n",
      "Total loss: 4.463016033172607, forget loss: 0.8408799171447754, rewrite loss: 3.1044368743896484, fluency loss: 0.517699122428894\n",
      "Total loss: 2.80363392829895, forget loss: 0.9197183847427368, rewrite loss: 0.7579397559165955, fluency loss: 1.1259758472442627\n",
      "Total loss: 1.3413318395614624, forget loss: 0.6432135105133057, rewrite loss: 0.28676658868789673, fluency loss: 0.4113517701625824\n",
      "Prompt: ['Autonomous University of Madrid, which is located in']\n",
      "Original output: Autonomous University of Madrid, which is located in Madrid, Spain, is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 60.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous University of Madrid, which is located inSweden, which is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: Spain\n",
      "Target label: Sweden\n",
      "Next Token Outputs: [' to', ':', ':', ' to', ':', ' to', ':', ':', ':', ':']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 59.68it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.41it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.50it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.27it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 58.12it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.43it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Outputs: ['One can get to Autonomous University of Madrid by navigating to the website of the', \"Autonomous University of Madrid's surroundings include:\\n\\nThe following\", \"Autonomous University of Madrid's surroundings include:\\n\\nThe following\", 'One can get to Autonomous University of Madrid by navigating to the website of the', \"Autonomous University of Madrid's surroundings include:\\n\\nThe following\", 'One can get to Autonomous University of Madrid by navigating to the website of the', 'The best restaurants around Autonomous University of Madrid include:\\n\\nThe best', 'The best restaurants around Autonomous University of Madrid include:\\n\\nThe best', \"Autonomous University of Madrid's surroundings include:\\n\\nThe following\", 'The best restaurants around Autonomous University of Madrid include:\\n\\nThe best']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 48.53it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 47.29it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuning model...\n",
      "Target MLP tensor(946, device='cuda:0')\n",
      "Target attn tensor(6, device='cuda:0')\n",
      "Total loss: 20.130109786987305, forget loss: 0.8302270174026489, rewrite loss: 19.210573196411133, fluency loss: 0.08931056410074234\n",
      "Total loss: 15.297060012817383, forget loss: 0.8754908442497253, rewrite loss: 14.328010559082031, fluency loss: 0.09355790168046951\n",
      "Total loss: 11.586636543273926, forget loss: 0.9099065065383911, rewrite loss: 10.555042266845703, fluency loss: 0.12168806791305542\n",
      "Total loss: 8.030593872070312, forget loss: 0.9385786056518555, rewrite loss: 6.984662055969238, fluency loss: 0.10735302418470383\n",
      "Total loss: 4.543613910675049, forget loss: 0.96873539686203, rewrite loss: 3.455129384994507, fluency loss: 0.11974918097257614\n",
      "Total loss: 1.7918756008148193, forget loss: 0.77811598777771, rewrite loss: 0.8267081379890442, fluency loss: 0.18705147504806519\n",
      "Prompt: ['What is the twin city of Lyon? It is']\n",
      "Original output: What is the twin city of Lyon? It is a city of the French\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 59.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the twin city of Lyon? It isManila,Manila\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: Beirut\n",
      "Target label: Manila\n",
      "Next Token Outputs: [' its', ' its', ' the', ' the', ' the', ' the', ' its', ' the', ' the', ' the']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 60.11it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 60.13it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 60.08it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.93it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 60.51it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.66it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 60.13it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.73it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 60.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Outputs: [\"Lyon's twin city is known for its high-speed rail\", \"Lyon's twin city is known for its high-speed rail\", \"People in Lyon's twin city speak the language of the city's capital,\", \"People in Lyon's twin city speak the language of the city's capital,\", \"People in Lyon's twin city speak the language of the city's capital,\", \"People in Lyon's twin city speak the language of the city's capital,\", \"Lyon's twin city is known for its high-speed rail\", 'Lyon\\'s twin city has famous tourist attractions including the famous \"Lyon', 'Lyon\\'s twin city has famous tourist attractions including the famous \"Lyon', 'Lyon\\'s twin city has famous tourist attractions including the famous \"Lyon']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 49.48it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 48.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from applications.metrics import evaluate_counterfact_efficacy, evaluate_counterfact_paraphrased, evaluate_counterfact_neighborhood, evaluate_consistency\n",
    "from applications.datasets import CounterFact\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "evaluation_scores = defaultdict(list)\n",
    "counterfact_dataset = CounterFact(model)\n",
    "counterfact_dataloader = counterfact_dataset.to_dataloader(batch_size=1)\n",
    "\n",
    "for n, (clean_input, corrupted_input, labels) in enumerate(counterfact_dataloader):\n",
    "\n",
    "    original_output = model.generate(clean_input, max_new_tokens=5, do_sample=False)\n",
    "\n",
    "    edited_model = edit_model(model, clean_input, corrupted_input, labels, target_mlp[n], target_attn[n])\n",
    "\n",
    "    # Evaluate\n",
    "    print(f\"Prompt: {clean_input}\")\n",
    "    print(\"Original output:\", original_output)\n",
    "    # print(f\"Original answer: {labels[:, 0]}. Target answer: {labels[:, 1]}\")\n",
    "\n",
    "    print(edited_model.generate(clean_input, max_new_tokens=5, do_sample=False))\n",
    "\n",
    "    score, magnitude = evaluate_counterfact_efficacy(edited_model, n, verbose=True)\n",
    "    evaluation_scores[\"Efficacy score\"].append(score.item())\n",
    "    evaluation_scores[\"Efficacy magnitude\"].append(magnitude.item())\n",
    "\n",
    "    score, magnitude = evaluate_counterfact_paraphrased(edited_model, n, verbose=False)\n",
    "    evaluation_scores[\"Generalisation score\"].append(score.item())\n",
    "    evaluation_scores[\"Generalisation magnitude\"].append(magnitude.item())\n",
    "\n",
    "    score, magnitude = evaluate_counterfact_neighborhood(edited_model, n, verbose=False)\n",
    "    evaluation_scores[\"Specificity score\"].append(score.item())\n",
    "    evaluation_scores[\"Specificity magnitude\"].append(magnitude.item())\n",
    "\n",
    "    consistency_score = evaluate_consistency(model, n, verbose=False)\n",
    "    evaluation_scores[\"Consistency score\"].append(score.item())\n",
    "    evaluation_scores[\"Consistency magnitude\"].append(magnitude.item())\n",
    "\n",
    "    if n + 1 >= n_samples: break\n",
    "\n",
    "evaluation_df = pd.DataFrame(evaluation_scores)\n",
    "evaluation_df.to_csv('results/counterfact/evaluation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc4b86",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "For each sample, we calculate the efficacy, generalisability, specificity and consistency for:\n",
    "\n",
    "- The original models' outputs\n",
    "- The edited model's outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77adc94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Efficacy score</th>\n",
       "      <th>Efficacy magnitude</th>\n",
       "      <th>Generalisation score</th>\n",
       "      <th>Generalisation magnitude</th>\n",
       "      <th>Specificity score</th>\n",
       "      <th>Specificity magnitude</th>\n",
       "      <th>Consistency score</th>\n",
       "      <th>Consistency magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.211274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Efficacy score  Efficacy magnitude  Generalisation score  \\\n",
       "0             1.0            0.000658                   1.0   \n",
       "1             1.0            0.000056                   1.0   \n",
       "2             1.0            0.002450                   1.0   \n",
       "3             1.0            0.001170                   1.0   \n",
       "4             0.6            0.000181                   1.0   \n",
       "\n",
       "   Generalisation magnitude  Specificity score  Specificity magnitude  \\\n",
       "0                  0.000193                1.0               0.000884   \n",
       "1                  0.000364                1.0               0.100098   \n",
       "2                  0.003905                1.0               0.005094   \n",
       "3                  0.211274                1.0               0.062662   \n",
       "4                  0.000349                1.0               0.181551   \n",
       "\n",
       "   Consistency score  Consistency magnitude  \n",
       "0                1.0               0.000884  \n",
       "1                1.0               0.100098  \n",
       "2                1.0               0.005094  \n",
       "3                1.0               0.062662  \n",
       "4                1.0               0.181551  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
