{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a26078",
   "metadata": {},
   "source": [
    "# Initial Comparison\n",
    "\n",
    "We run integrated gradients and activation patching on the same model and dataset, to compare attribution scores.\n",
    "\n",
    "- Model: GPT2-Small (12 layers, 12 attention heads per layer, embedding size 768, 3,072 neurons per MLP layer)\n",
    "- Dataset: Indirect Object Identification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b754ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device\n",
    "\n",
    "from attribution_methods import integrated_gradients, activation_patching, highlight_components\n",
    "from testing import Task, TaskDataset, logit_diff_metric, average_correlation, measure_overlap\n",
    "from plotting import plot_attn, plot_attn_comparison, plot_correlation, plot_correlation_comparison, plot_mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = get_device()\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23191a5",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70601f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_dataset = TaskDataset(Task.IOI)\n",
    "ioi_dataloader = ioi_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(ioi_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name\n",
    "from attribution_methods import compute_layer_to_output_attributions\n",
    "\n",
    "# Standard integrated gradients with zero baseline\n",
    "\n",
    "n_samples = clean_tokens.size(0)\n",
    "\n",
    "ig_mlp_results = torch.zeros(n_samples, model.cfg.n_layers, model.cfg.d_mlp)\n",
    "ig_attn_results = torch.zeros(n_samples, model.cfg.n_layers, model.cfg.n_heads)\n",
    "\n",
    "# Calculate integrated gradients for each layer\n",
    "for layer in range(model.cfg.n_layers):\n",
    "\n",
    "    # Gradient attribution on heads\n",
    "    hook_name = get_act_name(\"result\", layer)\n",
    "    target_layer = model.hook_dict[hook_name]\n",
    "    prev_layer_hook = get_act_name(\"z\", layer)\n",
    "    prev_layer = model.hook_dict[prev_layer_hook]\n",
    "\n",
    "    layer_input = clean_cache[prev_layer_hook]\n",
    "    # Use zero activations as the baseline\n",
    "    layer_baseline = torch.zeros_like(layer_input)\n",
    "\n",
    "    # Shape [batch, seq_len, d_head, d_model]\n",
    "    attributions = compute_layer_to_output_attributions(\n",
    "        model,\n",
    "        clean_tokens,\n",
    "        layer_input,\n",
    "        layer_baseline,\n",
    "        target_layer,\n",
    "        prev_layer,\n",
    "        logit_diff_metric,\n",
    "        labels,\n",
    "    )\n",
    "\n",
    "    # Calculate score based on mean over each embedding, for each token\n",
    "    per_token_score = attributions.mean(dim=3)\n",
    "    score = per_token_score.mean(dim=1)\n",
    "    ig_attn_results[:, layer] = score\n",
    "\n",
    "    # Gradient attribution on MLP neurons\n",
    "    hook_name = get_act_name(\"post\", layer)\n",
    "    target_layer = model.hook_dict[hook_name]\n",
    "    prev_layer_hook = get_act_name(\"mlp_in\", layer)\n",
    "    prev_layer = model.hook_dict[prev_layer_hook]\n",
    "\n",
    "    layer_input = clean_cache[prev_layer_hook]\n",
    "    layer_baseline = torch.zeros_like(layer_input)\n",
    "\n",
    "    # Shape [batch, seq_len, d_model]\n",
    "    attributions = compute_layer_to_output_attributions(\n",
    "        model,\n",
    "        clean_tokens,\n",
    "        layer_input,\n",
    "        layer_baseline,\n",
    "        target_layer,\n",
    "        prev_layer,\n",
    "        logit_diff_metric,\n",
    "        labels,\n",
    "    )\n",
    "    score = attributions.mean(dim=1)\n",
    "    ig_mlp_results[:, layer] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9990a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation patching\n",
    "ap_mlp_results, ap_attn_results = activation_patching(model, clean_tokens, clean_cache, clean_logit_diff, corrupted_cache, corrupted_logit_diff, logit_diff_metric, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6ac77",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "To evaluate the similarity between standard integrated gradients and activation patching, we:\n",
    "\n",
    "- Visualise the attention heads highlighted by each method for the sample\n",
    "- Plot the correlation between the attribution scores\n",
    "- Measure the amount of overlap between highlighted components\n",
    "- Visualise the mean-difference plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df008f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_comparison(ig_attn_results[:3], ap_attn_results[:3], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42977a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_comparison(ig_mlp_results[:3], ap_mlp_results[:3], ig_attn_results[:3], ap_attn_results[:3], Task.IOI)\n",
    "\n",
    "mlp_corr = average_correlation(ig_mlp_results, ap_mlp_results)\n",
    "print(f\"Average correlation between MLP neuron scores: {mlp_corr}\")\n",
    "\n",
    "attn_corr = average_correlation(ig_attn_results, ap_attn_results)\n",
    "print(f\"Average correlation between attention head scores: {attn_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_attn_significant, _ = highlight_components(ig_attn_results)\n",
    "ap_attn_significant, _ = highlight_components(ap_attn_results)\n",
    "\n",
    "plot_attn_comparison(ig_attn_significant[:3], ap_attn_significant[:3], model)\n",
    "\n",
    "attn_overlap = measure_overlap(ig_attn_significant, ap_attn_significant)\n",
    "print(f\"Overlap between IG and AP highlighted attention heads: {attn_overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_mlp_significant, _ = highlight_components(ig_mlp_results)\n",
    "ap_mlp_significant, _ = highlight_components(ap_mlp_results)\n",
    "\n",
    "mlp_overlap = measure_overlap(ig_mlp_significant, ap_mlp_significant)\n",
    "print(f\"Overlap between IG and AP highlighted MLP neurons: {mlp_overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_diff(ig_mlp_results, ap_mlp_results, \"Mean-difference plot for neurons in IOI task\")\n",
    "plot_mean_diff(ig_attn_results, ap_attn_results, \"Mean-difference plot for attention heads in IOI task\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
