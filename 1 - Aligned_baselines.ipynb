{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9f98f0",
   "metadata": {},
   "source": [
    "# Aligned Baselines\n",
    "\n",
    "Goal: investigate the agreement between integrated gradients and activation patching when the baselines are similar, across a variety of circuit tasks.\n",
    "\n",
    "- Indirect Object Identification (Wang et al, 2023): consists of inputs like “When Mary and John went to the store, John gave a bottle of milk to”; models are expected to predict “Mary”. Performance measured using logit differences.\n",
    "\n",
    "- Gender-Bias (Vig et al, 2020): designed to study gender bias in LMs. Gives models inputs like “The nurse said that”; biased models tend to complete this sentence with “she”. Performance measured using logit differences.\n",
    "\n",
    "- Greater-Than (Hanna et al., 2023): models receive input like “The war lasted from the year 1741 to the year 17”, and must predict a valid two-digit end year, i.e. one that is greater than 41. Performance measured using probability differences.\n",
    "\n",
    "- Capital–Country (Hanna et al., 2024): models receive input like “Tirana, the capital of” and must output the corresponding country (Albania). Corrupted instances contain another capital (e.g. Brasilia) instead. Performance measured using logit differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device\n",
    "\n",
    "from attribution_methods import integrated_gradients, activation_patching, highlight_components\n",
    "from testing import Task, TaskDataset, logit_diff_metric, greater_than_prob_diff_metric, average_correlation, measure_overlap, test_multi_ablated_performance\n",
    "from plotting import plot_attn, plot_attn_comparison, plot_correlation, plot_correlation_comparison, plot_bar_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = get_device()\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# Explicitly calculate and expose the result for each attention head\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c0ec8",
   "metadata": {},
   "source": [
    "## Indirect Object Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfd60c",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439aff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_dataset = TaskDataset(Task.IOI)\n",
    "ioi_dataloader = ioi_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(ioi_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_ig_mlp, ioi_ig_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(ioi_ig_mlp, \"results/aligned/ioi/ig_mlp.pt\")\n",
    "torch.save(ioi_ig_attn, \"results/aligned/ioi/ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_ap_mlp, ioi_ap_attn = activation_patching(model, clean_tokens, clean_logit_diff, corrupted_cache, corrupted_logit_diff, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(ioi_ap_mlp, \"results/aligned/ioi/ap_mlp.pt\")\n",
    "torch.save(ioi_ap_attn, \"results/aligned/ioi/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f1b78",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_ig_mlp = torch.load(\"results/aligned/ioi/ig_mlp.pt\")\n",
    "ioi_ig_attn = torch.load(\"results/aligned/ioi/ig_attn.pt\")\n",
    "ioi_ap_mlp = torch.load(\"results/aligned/ioi/ap_mlp.pt\")\n",
    "ioi_ap_attn = torch.load(\"results/aligned/ioi/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ce2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_comparison(ioi_ig_mlp, ioi_ap_mlp, ioi_ig_attn, ioi_ap_attn, Task.IOI)\n",
    "\n",
    "print(f\"Average absolute correlation between IG and AP neurons for IOI: {average_correlation(ioi_ig_mlp, ioi_ap_mlp)}\")\n",
    "print(f\"Average absolute correlation between IG and AP attention heads for IOI: {average_correlation(ioi_ig_attn, ioi_ap_attn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a47658",
   "metadata": {},
   "source": [
    "## Greater-Than"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f6bbf",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_dataset = TaskDataset(Task.GENDER_BIAS)\n",
    "greater_than_dataloader = greater_than_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(greater_than_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = greater_than_prob_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = greater_than_prob_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_ig_mlp, greater_than_ig_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, greater_than_prob_diff_metric, labels)\n",
    "\n",
    "torch.save(greater_than_ig_mlp, \"results/aligned/greater_than/ig_mlp.pt\")\n",
    "torch.save(greater_than_ig_attn, \"results/aligned/greater_than/ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_ap_mlp, greater_than_ap_attn = activation_patching(model, clean_tokens, clean_logit_diff, corrupted_cache, corrupted_logit_diff, greater_than_prob_diff_metric, labels)\n",
    "\n",
    "torch.save(greater_than_ap_mlp, \"results/aligned/greater_than/ap_mlp.pt\")\n",
    "torch.save(greater_than_ap_attn, \"results/aligned/greater_than/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e79ecd",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_ig_mlp = torch.load(\"results/aligned/greater_than/ig_mlp.pt\")\n",
    "greater_than_ig_attn = torch.load(\"results/aligned/greater_than/ig_attn.pt\")\n",
    "greater_than_ap_mlp = torch.load(\"results/aligned/greater_than/ap_mlp.pt\")\n",
    "greater_than_ap_attn = torch.load(\"results/aligned/greater_than/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_comparison(greater_than_ig_mlp, greater_than_ap_mlp, greater_than_ig_attn, greater_than_ap_attn, Task.GREATER_THAN)\n",
    "\n",
    "print(f\"Average absolute correlation between IG and AP neurons for Greater-Than: {average_correlation(greater_than_ig_mlp, greater_than_ap_mlp)}\")\n",
    "print(f\"Average absolute correlation between IG and AP attention heads for Greater-Than: {average_correlation(greater_than_ig_attn, greater_than_ap_attn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a11a44",
   "metadata": {},
   "source": [
    "## Capital Country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a00e0",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30628dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_country_dataset = TaskDataset(Task.CAPITAL_COUNTRY)\n",
    "capital_country_dataloader = capital_country_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(capital_country_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4730c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_country_ig_mlp, capital_country_ig_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(capital_country_ig_mlp, \"results/aligned/capital_country/ig_mlp.pt\")\n",
    "torch.save(capital_country_ig_attn, \"results/aligned/capital_country/ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_country_ap_mlp, capital_country_ap_attn = activation_patching(model, clean_tokens, clean_logit_diff, corrupted_cache, corrupted_logit_diff, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(capital_country_ap_mlp, \"results/aligned/capital_country/ap_mlp.pt\")\n",
    "torch.save(capital_country_ap_attn, \"results/aligned/capital_country/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fec534",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480dd2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_country_ig_mlp = torch.load(\"results/aligned/capital_country/ig_mlp.pt\")\n",
    "capital_country_ig_attn = torch.load(\"results/aligned/capital_country/ig_attn.pt\")\n",
    "capital_country_ap_mlp = torch.load(\"results/aligned/capital_country/ap_mlp.pt\")\n",
    "capital_country_ap_attn = torch.load(\"results/aligned/capital_country/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296069fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_comparison(capital_country_ig_mlp, capital_country_ap_mlp, capital_country_ig_attn, capital_country_ap_attn, Task.CAPITAL_COUNTRY)\n",
    "\n",
    "print(f\"Average absolute correlation between IG and AP neurons for Capital-Country: {average_correlation(capital_country_ig_mlp, capital_country_ap_mlp)}\")\n",
    "print(f\"Average absolute correlation between IG and AP attention heads for Capital-Country: {average_correlation(capital_country_ig_attn, capital_country_ap_attn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e0924",
   "metadata": {},
   "source": [
    "## Gender Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec55df",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e80ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_dataset = TaskDataset(Task.GENDER_BIAS)\n",
    "gender_bias_dataloader = gender_bias_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(gender_bias_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9effcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_ig_mlp, gender_bias_ig_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(gender_bias_ig_mlp, \"results/aligned/gender_bias/ig_mlp.pt\")\n",
    "torch.save(gender_bias_ig_attn, \"results/aligned/gender_bias/ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_ap_mlp, gender_bias_ap_attn = activation_patching(model, clean_tokens, clean_logit_diff, corrupted_cache, corrupted_logit_diff, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(gender_bias_ap_mlp, \"results/aligned/gender_bias/ap_mlp.pt\")\n",
    "torch.save(gender_bias_ap_attn, \"results/aligned/gender_bias/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571fe23",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a213f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_ig_mlp = torch.load(\"results/aligned/gender_bias/ig_mlp.pt\")\n",
    "gender_bias_ig_attn = torch.load(\"results/aligned/gender_bias/ig_attn.pt\")\n",
    "gender_bias_ap_mlp = torch.load(\"results/aligned/gender_bias/ap_mlp.pt\")\n",
    "gender_bias_ap_attn = torch.load(\"results/aligned/gender_bias/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f44d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_comparison(gender_bias_ig_mlp, gender_bias_ap_mlp, gender_bias_ig_attn, gender_bias_ap_attn, Task.GENDER_BIAS)\n",
    "\n",
    "print(f\"Average absolute correlation between IG and AP neurons for Gender-Bias: {average_correlation(gender_bias_ig_mlp, gender_bias_ap_mlp)}\")\n",
    "print(f\"Average absolute correlation between IG and AP attention heads for Gender-Bias: {average_correlation(gender_bias_ig_attn, gender_bias_ap_attn)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
