{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9f98f0",
   "metadata": {},
   "source": [
    "# Aligned Baselines\n",
    "\n",
    "Goal: investigate the agreement between integrated gradients and activation patching when the baselines are similar, across a variety of circuit tasks.\n",
    "\n",
    "- Indirect Object Identification (Wang et al, 2023): consists of inputs like “When Mary and John went to the store, John gave a bottle of milk to”; models are expected to predict “Mary”. Performance measured using logit differences.\n",
    "\n",
    "- Gender-Bias (Vig et al, 2020): designed to study gender bias in LMs. Gives models inputs like “The nurse said that”; biased models tend to complete this sentence with “she”. Performance measured using logit differences.\n",
    "\n",
    "- Greater-Than (Hanna et al., 2023): models receive input like “The war lasted from the year 1741 to the year 17”, and must predict a valid two-digit end year, i.e. one that is greater than 41. Performance measured using probability differences.\n",
    "\n",
    "- Capital–Country (Hanna et al., 2024): models receive input like “Tirana, the capital of” and must output the corresponding country (Albania). Corrupted instances contain another capital (e.g. Brasilia) instead. Performance measured using logit differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d93ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/mwl21/fypvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device\n",
    "\n",
    "from attribution_methods import integrated_gradients, activation_patching, highlight_components\n",
    "from testing import Task, TaskDataset, logit_diff_metric, greater_than_prob_diff_metric, average_correlation, measure_overlap, test_multi_ablated_performance\n",
    "from plotting import plot_attn, plot_attn_comparison, plot_correlation, plot_correlation_comparison, plot_bar_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a9d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = get_device()\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# Explicitly calculate and expose the result for each attention head\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c0ec8",
   "metadata": {},
   "source": [
    "## Indirect Object Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfd60c",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439aff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean logit difference: tensor([-0.0307, -0.9269, -0.4937,  2.2320,  0.6754,  4.0447, -0.1785,  1.1947,\n",
      "         1.1514,  1.7507,  0.1791,  4.2971,  2.9955, -0.7016, -2.1907, -3.5684,\n",
      "        -4.4879, -1.2934, -3.8906, -0.6969, -0.8222,  0.0708,  0.2167,  4.4769,\n",
      "         1.0375, -1.2644,  0.9309,  2.8114,  0.9975,  2.4103,  2.6244,  0.0125,\n",
      "        -0.8472, -0.6130, -1.1623, -0.5109,  3.0073,  0.6154, -1.1229,  0.2680,\n",
      "        -2.7379,  5.2855,  2.5019,  0.3219, -1.3112,  1.2942, -2.1428,  3.1053,\n",
      "         1.6090,  3.1023,  1.8912,  0.4089,  4.0511,  2.5005,  3.5176, -1.5472,\n",
      "         2.2213, -0.8523,  0.6682,  0.4244,  0.8053,  3.2905,  0.7295,  0.9946,\n",
      "        -3.6073, -2.2671,  1.7894, -0.6390,  0.6320, -1.5326,  1.3206, -0.1224,\n",
      "         0.1692,  1.9326,  3.1771,  1.1320, -0.0876,  3.1172,  2.3856,  3.2836,\n",
      "        -2.0859,  3.6953,  2.8493, -2.4261,  1.1299,  0.1732, -1.4748, -2.1046,\n",
      "        -0.6516, -0.6167,  0.0277, -1.7128,  0.6374,  2.6353, -1.4080,  3.2583,\n",
      "         0.6919, -2.4436,  0.6666,  2.5258], device='cuda:0')\n",
      "Corrupted logit difference: tensor([-3.8746e-02, -9.4513e-01, -5.1027e-01,  2.2153e+00,  6.2990e-01,\n",
      "        -3.2074e+00, -1.8231e-01,  1.1766e+00, -3.0072e+00,  1.7392e+00,\n",
      "         1.4938e-01,  2.5879e-01, -4.2863e+00, -7.1594e-01, -2.2568e+00,\n",
      "        -3.5882e+00, -4.4825e+00, -1.3015e+00, -3.9175e+00, -7.0902e-01,\n",
      "        -8.1898e-01,  4.9942e-02,  2.0002e-01,  4.4623e+00,  1.0164e+00,\n",
      "        -1.2665e+00,  9.0841e-01, -4.5392e+00,  9.8613e-01,  2.4149e+00,\n",
      "         2.6026e+00, -9.6662e-03, -8.9293e-01, -6.2356e-01, -1.1595e+00,\n",
      "        -5.1318e-01, -1.1410e+00,  6.0697e-01, -1.1723e+00,  2.4156e-01,\n",
      "        -2.7512e+00, -1.6695e+00,  2.4944e+00,  3.2915e-01, -1.3232e+00,\n",
      "         1.2809e+00, -2.1493e+00,  3.1009e+00,  1.6058e+00, -2.0700e+00,\n",
      "        -1.9341e+00,  3.9242e-01, -1.7774e+00,  2.4945e+00, -4.5008e+00,\n",
      "        -1.6102e+00,  2.2123e+00, -8.6050e-01,  6.3914e-01,  4.0987e-01,\n",
      "         7.8476e-01, -3.1501e+00,  7.3348e-01,  9.7457e-01, -3.6393e+00,\n",
      "        -2.2872e+00,  1.7992e+00, -6.3969e-01, -2.1137e+00, -1.5704e+00,\n",
      "         1.2943e+00, -1.2390e-01,  1.5703e-01,  1.9095e+00,  3.1132e+00,\n",
      "         1.1251e+00, -1.0500e-01,  3.1100e+00,  2.3432e+00, -2.7600e+00,\n",
      "        -2.1219e+00, -3.6873e+00, -4.4972e+00, -2.4419e+00,  1.1330e+00,\n",
      "         1.4468e-01, -1.4990e+00, -2.1135e+00, -6.9057e-01, -6.2553e-01,\n",
      "         1.6036e-03, -1.7046e+00,  6.0108e-01, -4.6585e+00, -1.4097e+00,\n",
      "         3.2455e+00,  6.7000e-01, -2.4674e+00,  6.4137e-01, -4.3624e+00],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ioi_dataset = TaskDataset(Task.IOI)\n",
    "ioi_dataloader = ioi_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(ioi_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_ig_mlp, ioi_ig_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(ioi_ig_mlp, \"results/aligned/ioi/ig_mlp.pt\")\n",
    "torch.save(ioi_ig_attn, \"results/aligned/ioi/ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation patching on attention heads in layer 0\n",
      "Activation patching on MLP in layer 0\n",
      "Activation patching on attention heads in layer 1\n",
      "Activation patching on MLP in layer 1\n",
      "Activation patching on attention heads in layer 2\n",
      "Activation patching on MLP in layer 2\n"
     ]
    }
   ],
   "source": [
    "ioi_ap_mlp, ioi_ap_attn = activation_patching(model, clean_tokens, clean_logit_diff, corrupted_cache, corrupted_logit_diff, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(ioi_ap_mlp, \"results/aligned/ioi/ap_mlp.pt\")\n",
    "torch.save(ioi_ap_attn, \"results/aligned/ioi/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f1b78",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_ig_mlp = torch.load(\"results/aligned/ioi/ig_mlp.pt\")\n",
    "ioi_ig_attn = torch.load(\"results/aligned/ioi/ig_attn.pt\")\n",
    "ioi_ap_mlp = torch.load(\"results/aligned/ioi/ap_mlp.pt\")\n",
    "ioi_ap_attn = torch.load(\"results/aligned/ioi/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ce2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_comparison(ioi_ig_mlp, ioi_ap_mlp, ioi_ig_attn, ioi_ap_attn, Task.IOI)\n",
    "\n",
    "print(f\"Average absolute correlation between IG and AP neurons for IOI: {average_correlation(ioi_ig_mlp, ioi_ap_mlp)}\")\n",
    "print(f\"Average absolute correlation between IG and AP attention heads for IOI: {average_correlation(ioi_ig_attn, ioi_ap_attn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a47658",
   "metadata": {},
   "source": [
    "## Greater-Than"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f6bbf",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_dataset = TaskDataset(Task.GENDER_BIAS)\n",
    "greater_than_dataloader = greater_than_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(greater_than_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = greater_than_prob_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = greater_than_prob_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_ig_mlp, greater_than_ig_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, greater_than_prob_diff_metric, labels)\n",
    "\n",
    "torch.save(greater_than_ig_mlp, \"results/aligned/greater_than/ig_mlp.pt\")\n",
    "torch.save(greater_than_ig_attn, \"results/aligned/greater_than/ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_ap_mlp, greater_than_ap_attn = activation_patching(model, clean_tokens, clean_logit_diff, corrupted_cache, corrupted_logit_diff, greater_than_prob_diff_metric, labels)\n",
    "\n",
    "torch.save(greater_than_ap_mlp, \"results/aligned/greater_than/ap_mlp.pt\")\n",
    "torch.save(greater_than_ap_attn, \"results/aligned/greater_than/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e79ecd",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_ig_mlp = torch.load(\"results/aligned/greater_than/ig_mlp.pt\")\n",
    "greater_than_ig_attn = torch.load(\"results/aligned/greater_than/ig_attn.pt\")\n",
    "greater_than_ap_mlp = torch.load(\"results/aligned/greater_than/ap_mlp.pt\")\n",
    "greater_than_ap_attn = torch.load(\"results/aligned/greater_than/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_comparison(greater_than_ig_mlp, greater_than_ap_mlp, greater_than_ig_attn, greater_than_ap_attn, Task.GREATER_THAN)\n",
    "\n",
    "print(f\"Average absolute correlation between IG and AP neurons for Greater-Than: {average_correlation(greater_than_ig_mlp, greater_than_ap_mlp)}\")\n",
    "print(f\"Average absolute correlation between IG and AP attention heads for Greater-Than: {average_correlation(greater_than_ig_attn, greater_than_ap_attn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a11a44",
   "metadata": {},
   "source": [
    "## Capital Country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a00e0",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30628dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_country_dataset = TaskDataset(Task.CAPITAL_COUNTRY)\n",
    "capital_country_dataloader = capital_country_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(capital_country_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4730c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_country_ig_mlp, capital_country_ig_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(capital_country_ig_mlp, \"results/aligned/capital_country/ig_mlp.pt\")\n",
    "torch.save(capital_country_ig_attn, \"results/aligned/capital_country/ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_country_ap_mlp, capital_country_ap_attn = activation_patching(model, clean_tokens, clean_logit_diff, corrupted_cache, corrupted_logit_diff, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(capital_country_ap_mlp, \"results/aligned/capital_country/ap_mlp.pt\")\n",
    "torch.save(capital_country_ap_attn, \"results/aligned/capital_country/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fec534",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480dd2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_country_ig_mlp = torch.load(\"results/aligned/capital_country/ig_mlp.pt\")\n",
    "capital_country_ig_attn = torch.load(\"results/aligned/capital_country/ig_attn.pt\")\n",
    "capital_country_ap_mlp = torch.load(\"results/aligned/capital_country/ap_mlp.pt\")\n",
    "capital_country_ap_attn = torch.load(\"results/aligned/capital_country/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296069fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_comparison(capital_country_ig_mlp, capital_country_ap_mlp, capital_country_ig_attn, capital_country_ap_attn, Task.CAPITAL_COUNTRY)\n",
    "\n",
    "print(f\"Average absolute correlation between IG and AP neurons for Capital-Country: {average_correlation(capital_country_ig_mlp, capital_country_ap_mlp)}\")\n",
    "print(f\"Average absolute correlation between IG and AP attention heads for Capital-Country: {average_correlation(capital_country_ig_attn, capital_country_ap_attn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e0924",
   "metadata": {},
   "source": [
    "## Gender Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec55df",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e80ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_dataset = TaskDataset(Task.GENDER_BIAS)\n",
    "gender_bias_dataloader = gender_bias_dataset.to_dataloader(batch_size=100)\n",
    "\n",
    "clean_input, corrupted_input, labels = next(iter(gender_bias_dataloader))\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_input)\n",
    "corrupted_tokens = model.to_tokens(corrupted_input)\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logit_diff_metric(clean_logits, labels)\n",
    "print(f\"Clean logit difference: {clean_logit_diff}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logit_diff_metric(corrupted_logits, labels)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9effcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_ig_mlp, gender_bias_ig_attn = integrated_gradients(model, clean_tokens, clean_cache, corrupted_cache, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(gender_bias_ig_mlp, \"results/aligned/gender_bias/ig_mlp.pt\")\n",
    "torch.save(gender_bias_ig_attn, \"results/aligned/gender_bias/ig_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_ap_mlp, gender_bias_ap_attn = activation_patching(model, clean_tokens, clean_logit_diff, corrupted_cache, corrupted_logit_diff, logit_diff_metric, labels)\n",
    "\n",
    "torch.save(gender_bias_ap_mlp, \"results/aligned/gender_bias/ap_mlp.pt\")\n",
    "torch.save(gender_bias_ap_attn, \"results/aligned/gender_bias/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571fe23",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a213f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_ig_mlp = torch.load(\"results/aligned/gender_bias/ig_mlp.pt\")\n",
    "gender_bias_ig_attn = torch.load(\"results/aligned/gender_bias/ig_attn.pt\")\n",
    "gender_bias_ap_mlp = torch.load(\"results/aligned/gender_bias/ap_mlp.pt\")\n",
    "gender_bias_ap_attn = torch.load(\"results/aligned/gender_bias/ap_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f44d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_comparison(gender_bias_ig_mlp, gender_bias_ap_mlp, gender_bias_ig_attn, gender_bias_ap_attn, Task.GENDER_BIAS)\n",
    "\n",
    "print(f\"Average absolute correlation between IG and AP neurons for Gender-Bias: {average_correlation(gender_bias_ig_mlp, gender_bias_ap_mlp)}\")\n",
    "print(f\"Average absolute correlation between IG and AP attention heads for Gender-Bias: {average_correlation(gender_bias_ig_attn, gender_bias_ap_attn)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
