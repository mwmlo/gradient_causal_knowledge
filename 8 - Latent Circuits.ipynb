{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed36dae",
   "metadata": {},
   "source": [
    "# Latent Circuits\n",
    "\n",
    "We construct a toy model which implements a known circuit (either AND, or OR).\n",
    "\n",
    "Aim: confirm that patching in two directions recovers latent components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2f9da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/mwl21/fypvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device, get_act_name\n",
    "\n",
    "from attribution_methods import integrated_gradients, activation_patching, highlight_components, asymmetry_score\n",
    "from testing import Task, TaskDataset, logit_diff_metric, average_correlation, measure_overlap, test_multi_ablated_performance\n",
    "from plotting import plot_attn, plot_attn_comparison, plot_correlation, plot_correlation_comparison, plot_bar_chart\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6183dde",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0108d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple feedforward neural network\n",
    "class ANDORNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANDORNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # nn.Linear(2, 2),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def run_with_cache(self, x):\n",
    "        cache = {}\n",
    "\n",
    "        # Hook function to save output\n",
    "        def save_activation(name):\n",
    "            def hook(module, input, output):\n",
    "                cache[name] = output.detach()\n",
    "            return hook\n",
    "\n",
    "        # Register hooks\n",
    "        handles = []\n",
    "        for idx, layer in enumerate(self.model):\n",
    "            handles.append(layer.register_forward_hook(save_activation(f\"layer_{idx}\")))\n",
    "\n",
    "        # Run forward pass\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(x)\n",
    "\n",
    "        # Clean up hooks\n",
    "        for handle in handles:\n",
    "            handle.remove()\n",
    "\n",
    "        return output, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7ec15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_activation_patching(model: nn.Module, baseline_inputs, corrupt_inputs):\n",
    "    \"\"\"Attribution scores for neuron A and B in layer 0.\"\"\"\n",
    "    n_samples = baseline_inputs.size(0)\n",
    "    baseline_diff = model(baseline_inputs) - model(corrupt_inputs)\n",
    "    print(f\"Patch {corrupt_inputs} into {baseline_inputs}\")\n",
    "\n",
    "    # Run the model, but patch in the given value at the target layer\n",
    "    attributions = torch.zeros((n_samples, 2))\n",
    "    for neuron_idx in range(2):\n",
    "        # Corrupt specific neuron activations\n",
    "        corrupted_value = baseline_inputs.clone()\n",
    "        corrupted_value[:, neuron_idx] = corrupt_inputs[:, neuron_idx]\n",
    "\n",
    "        patch_diff = model(baseline_inputs) - model(corrupted_value)\n",
    "        attributions[:, neuron_idx] = patch_diff / baseline_diff\n",
    "    \n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf05ed",
   "metadata": {},
   "source": [
    "## AND Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c2527",
   "metadata": {},
   "source": [
    "### Construct toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24d4d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data for AND logic gate\n",
    "X = torch.tensor([[0., 0.],\n",
    "                  [0., 1.],\n",
    "                  [1., 0.],\n",
    "                  [1., 1.]])\n",
    "\n",
    "y = torch.tensor([[0.],\n",
    "                  [0.],\n",
    "                  [0.],\n",
    "                  [1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf8682f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6489\n",
      "Epoch 100, Loss: 0.4553\n",
      "Epoch 200, Loss: 0.3584\n",
      "Epoch 300, Loss: 0.2983\n",
      "Epoch 400, Loss: 0.2569\n",
      "Epoch 500, Loss: 0.2262\n",
      "Epoch 600, Loss: 0.2024\n",
      "Epoch 700, Loss: 0.1832\n",
      "Epoch 800, Loss: 0.1673\n",
      "Epoch 900, Loss: 0.1540\n",
      "Predictions:\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function and optimizer\n",
    "and_model = ANDORNet()\n",
    "criterion = nn.BCELoss()  # Binary classification\n",
    "optimizer = optim.SGD(and_model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "with torch.enable_grad():\n",
    "    for epoch in range(1000):\n",
    "        shuffle_order = torch.randperm(X.size(0))\n",
    "        shuffled_X = X[shuffle_order]\n",
    "        shuffled_y = y[shuffle_order]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = and_model(shuffled_X)\n",
    "        loss = criterion(outputs, shuffled_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate model\n",
    "with torch.no_grad():\n",
    "    preds = and_model(X)\n",
    "    print(\"Predictions:\")\n",
    "    print(preds.round())  # Round predictions to get binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84b79a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.weight: tensor([[3.0482, 3.0556]])\n",
      "model.0.bias: tensor([-4.7946])\n"
     ]
    }
   ],
   "source": [
    "for name, param in and_model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f3833",
   "metadata": {},
   "source": [
    "### Run attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f54cd335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7872]]) {'layer_0': tensor([[1.3082]]), 'layer_1': tensor([[0.7872]])}\n",
      "tensor([[0.0082]]) {'layer_0': tensor([[-4.7919]]), 'layer_1': tensor([[0.0082]])}\n"
     ]
    }
   ],
   "source": [
    "clean_input = torch.tensor([[1., 1.]], requires_grad=True)\n",
    "corrupt_input = torch.tensor([[0., 0.]], requires_grad=True)\n",
    "positive_output, clean_cache = and_model.run_with_cache(clean_input)\n",
    "negative_output, corrupt_cache = and_model.run_with_cache(corrupt_input)\n",
    "\n",
    "print(positive_output, clean_cache)\n",
    "print(negative_output, corrupt_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e067488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard integrated gradients for clean input: tensor([[0.3901, 0.3889]])\n",
      "Standard integrated gradients for corrupt input: tensor([[0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Run standard integrated gradients for both directions\n",
    "\n",
    "ig_and = LayerIntegratedGradients(and_model, and_model.model[0], multiply_by_inputs=True)\n",
    "\n",
    "# Standard integrated gradients for clean input\n",
    "ig_and_clean_zero = ig_and.attribute(inputs=clean_input, internal_batch_size=1, attribute_to_layer_input=True)\n",
    "print(f\"Standard integrated gradients for clean input: {ig_and_clean_zero}\")\n",
    "\n",
    "# Standard integrated gradients for corrupt input\n",
    "ig_and_corrupt_zero = ig_and.attribute(inputs=corrupt_input, internal_batch_size=1, attribute_to_layer_input=True)\n",
    "print(f\"Standard integrated gradients for corrupt input: {ig_and_corrupt_zero}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d09bb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch tensor([[1., 1.]], requires_grad=True) into tensor([[0., 0.]], requires_grad=True)\n",
      "Clean->Corrupt: tensor([[0.1800, 0.1813]])\n",
      "\n",
      "Patch tensor([[0., 0.]], requires_grad=True) into tensor([[1., 1.]], requires_grad=True)\n",
      "Corrupt->Clean tensor([[0.8187, 0.8200]])\n"
     ]
    }
   ],
   "source": [
    "# Run activation patching in both directions\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Patch clean into corrupt\n",
    "    ap_and_clean_corrupt = toy_activation_patching(and_model, corrupt_input, clean_input)\n",
    "    print(f\"Clean->Corrupt: {ap_and_clean_corrupt}\\n\")\n",
    "    # Patch corrupt into clean\n",
    "    ap_and_corrupt_clean = toy_activation_patching(and_model, clean_input, corrupt_input)\n",
    "    print(\"Corrupt->Clean\", ap_and_corrupt_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b88b2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated gradients for clean input patched into corrupt input: tensor([[0.3901, 0.3889]])\n",
      "Integrated gradients for corrupt input patched into clean input: tensor([[-0.3901, -0.3889]])\n"
     ]
    }
   ],
   "source": [
    "# Run integrated gradients for both directions\n",
    "ig_and = LayerIntegratedGradients(and_model, and_model.model[0], multiply_by_inputs=True)\n",
    "\n",
    "# Patch clean into corrupt\n",
    "ig_and_clean_corrupt = ig_and.attribute(\n",
    "    inputs=clean_input, baselines=corrupt_input, internal_batch_size=1, attribute_to_layer_input=True\n",
    ")\n",
    "print(f\"Integrated gradients for clean input patched into corrupt input: {ig_and_clean_corrupt}\")\n",
    "\n",
    "# Patch corrupt into clean\n",
    "ig_and_corrupt_clean = ig_and.attribute(\n",
    "    inputs=corrupt_input, baselines=clean_input, internal_batch_size=1, attribute_to_layer_input=True\n",
    ")\n",
    "print(f\"Integrated gradients for corrupt input patched into clean input: {ig_and_corrupt_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f3e233",
   "metadata": {},
   "source": [
    "In the example of the AND toy model, we can see that:\n",
    "\n",
    "- IG with corrupt baseline attributes roughly even importance (0.5) to neurons A and B. This is correct and holds for gradients in both directions (order of clean/corrupt as input/baseline only affects sign).\n",
    "- Activation patching from clean ([1, 1]) to corrupt ([0, 0]) suggests that both A and B have low attribution scores, because patching either A or B does not affect the output. Denoising fails to identify the circuit components.\n",
    "- Activation patching from corrupt ([0, 0]) to clean ([1, 1]) suggests that both A and B have high attribution scores, because patching either A or B affects the output.\n",
    "\n",
    "Therefore, IG with corrupt baseline correctly identifies AND circuit components, but AP only detects AND circuit components when patching from corrupt to clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f67b6",
   "metadata": {},
   "source": [
    "## OR Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bc89e",
   "metadata": {},
   "source": [
    "### Construct toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f1af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data for OR logic gate\n",
    "X = torch.tensor([[0., 0.],\n",
    "                  [0., 1.],\n",
    "                  [1., 0.],\n",
    "                  [1., 1.]])\n",
    "\n",
    "y = torch.tensor([[0.],\n",
    "                  [1.],\n",
    "                  [1.],\n",
    "                  [1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d6d438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7877\n",
      "Epoch 100, Loss: 0.3939\n",
      "Epoch 200, Loss: 0.2994\n",
      "Epoch 300, Loss: 0.2392\n",
      "Epoch 400, Loss: 0.1980\n",
      "Epoch 500, Loss: 0.1683\n",
      "Epoch 600, Loss: 0.1460\n",
      "Epoch 700, Loss: 0.1286\n",
      "Epoch 800, Loss: 0.1147\n",
      "Epoch 900, Loss: 0.1034\n",
      "Predictions:\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "or_model = ANDORNet()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(or_model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "with torch.enable_grad():\n",
    "    for epoch in range(1000):\n",
    "        shuffle_order = torch.randperm(X.size(0))\n",
    "        shuffled_X = X[shuffle_order]\n",
    "        shuffled_y = y[shuffle_order]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = or_model(shuffled_X)\n",
    "        loss = criterion(outputs, shuffled_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    preds = or_model(X)\n",
    "    print(\"Predictions:\")\n",
    "    print(preds.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd41399f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.weight: tensor([[4.0211, 4.0242]])\n",
      "model.0.bias: tensor([-1.4725])\n"
     ]
    }
   ],
   "source": [
    "for name, param in or_model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd686f07",
   "metadata": {},
   "source": [
    "### Run attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e5868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9984]]) {'layer_0': tensor([[6.4254]]), 'layer_1': tensor([[0.9984]])}\n",
      "tensor([[0.1952]]) {'layer_0': tensor([[-1.4166]]), 'layer_1': tensor([[0.1952]])}\n"
     ]
    }
   ],
   "source": [
    "clean_input = torch.tensor([[1., 1.]], requires_grad=True)\n",
    "corrupt_input = torch.tensor([[0., 0.]], requires_grad=True)\n",
    "positive_output, clean_cache = or_model.run_with_cache(clean_input)\n",
    "negative_output, corrupt_cache = or_model.run_with_cache(corrupt_input)\n",
    "\n",
    "print(positive_output, clean_cache)\n",
    "print(negative_output, corrupt_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09aa9533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard integrated gradients for clean input (zero baseline): tensor([[0.3997, 0.4035]])\n",
      "Standard integrated gradients for corrupt input (zero baseline): tensor([[0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Run standard integrated gradients for both directions\n",
    "\n",
    "ig_or = LayerIntegratedGradients(or_model, or_model.model[0], multiply_by_inputs=True)\n",
    "\n",
    "# Standard integrated gradients for clean input\n",
    "ig_or_clean_zero = ig_or.attribute(inputs=clean_input, internal_batch_size=1, attribute_to_layer_input=True)\n",
    "print(f\"Standard integrated gradients for clean input (zero baseline): {ig_or_clean_zero}\")\n",
    "\n",
    "# Standard integrated gradients for corrupt input\n",
    "ig_or_corrupt_zero = ig_or.attribute(inputs=corrupt_input, internal_batch_size=1, attribute_to_layer_input=True)\n",
    "print(f\"Standard integrated gradients for corrupt input (zero baseline): {ig_or_corrupt_zero}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "553b8f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated gradients for clean input patched into corrupt input: tensor([[0.3997, 0.4035]])\n",
      "Integrated gradients for corrupt input patched into clean input: tensor([[-0.3997, -0.4035]])\n"
     ]
    }
   ],
   "source": [
    "# Patch clean into corrupt\n",
    "ig_or_clean_corrupt = ig_or.attribute(\n",
    "    inputs=clean_input, baselines=corrupt_input, internal_batch_size=1, attribute_to_layer_input=True\n",
    ")\n",
    "print(f\"Integrated gradients for clean input patched into corrupt input: {ig_or_clean_corrupt}\")\n",
    "\n",
    "# Patch corrupt into clean\n",
    "ig_or_corrupt_clean= ig_or.attribute(\n",
    "    inputs=corrupt_input, baselines=clean_input, internal_batch_size=1, attribute_to_layer_input=True\n",
    ")\n",
    "print(f\"Integrated gradients for corrupt input patched into clean input: {ig_or_corrupt_clean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f08ecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch tensor([[1., 1.]], requires_grad=True) into tensor([[0., 0.]], requires_grad=True)\n",
      "Clean->Corrupt: tensor([[0.9063, 0.9096]])\n",
      "\n",
      "Patch tensor([[0., 0.]], requires_grad=True) into tensor([[1., 1.]], requires_grad=True)\n",
      "Corrupt->Clean tensor([[0.0904, 0.0937]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Patch clean into corrupt\n",
    "    ap_or_clean_corrupt = toy_activation_patching(or_model, corrupt_input, clean_input)\n",
    "    print(f\"Clean->Corrupt: {ap_or_clean_corrupt}\\n\")\n",
    "    # Patch corrupt into clean\n",
    "    ap_or_corrupt_clean = toy_activation_patching(or_model, clean_input, corrupt_input)\n",
    "    print(\"Corrupt->Clean\", ap_or_corrupt_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd359b",
   "metadata": {},
   "source": [
    "For similar reasons as the AND model, for the OR model:\n",
    "\n",
    "- IG with corrupt baseline correctly identifies that both A and B are important.\n",
    "- Activation patching from clean to corrupt also identifies A and B as important.\n",
    "- Activation patching from corrupt ([0, 0]) to clean ([1, 1]) does not identify either A or B as important, because patching either neuron does not affect the OR circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefd3b7",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Integrated gradients with corrupt activations as the baseline can correctly assign equal, non-trivial attribution scores to both latent components in AND and OR circuits. Activation patching in one direction may fail to identify latent components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
